{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer.Models import Transformer, LowRankTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_src_vocab_size=9521\n",
    "opt_trg_vocab_size=9521\n",
    "opt_src_pad_idx=1\n",
    "opt_trg_pad_idx=1\n",
    "opt_proj_share_weight=True\n",
    "opt_embs_share_weight=True\n",
    "opt_d_k=64\n",
    "opt_d_v=64\n",
    "opt_d_model=512\n",
    "opt_d_word_vec=512\n",
    "opt_d_inner_hid=2048\n",
    "opt_n_layers=6\n",
    "opt_n_head=8\n",
    "opt_dropout=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_transformer = LowRankTransformer(\n",
    "    opt_src_vocab_size,\n",
    "    opt_trg_vocab_size,\n",
    "    src_pad_idx=opt_src_pad_idx,\n",
    "    trg_pad_idx=opt_trg_pad_idx,\n",
    "    trg_emb_prj_weight_sharing=opt_proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=opt_embs_share_weight,\n",
    "    d_k=opt_d_k,\n",
    "    d_v=opt_d_v,\n",
    "    d_model=opt_d_model,\n",
    "    d_word_vec=opt_d_word_vec,\n",
    "    d_inner=opt_d_inner_hid,\n",
    "    n_layers=opt_n_layers,\n",
    "    n_head=opt_n_head,\n",
    "    dropout=opt_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 encoder.src_word_emb.weight torch.Size([9521, 512])\n",
      "1 encoder.position_enc.pos_table torch.Size([1, 200, 512])\n",
      "2 encoder.layer_stack.0.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "3 encoder.layer_stack.0.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "4 encoder.layer_stack.0.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "5 encoder.layer_stack.0.slf_attn.fc.weight torch.Size([512, 512])\n",
      "6 encoder.layer_stack.0.slf_attn.layer_norm.weight torch.Size([512])\n",
      "7 encoder.layer_stack.0.slf_attn.layer_norm.bias torch.Size([512])\n",
      "8 encoder.layer_stack.0.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "9 encoder.layer_stack.0.pos_ffn.w_1.bias torch.Size([2048])\n",
      "10 encoder.layer_stack.0.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "11 encoder.layer_stack.0.pos_ffn.w_2.bias torch.Size([512])\n",
      "12 encoder.layer_stack.0.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "13 encoder.layer_stack.0.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "14 encoder.layer_stack.1.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "15 encoder.layer_stack.1.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "16 encoder.layer_stack.1.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "17 encoder.layer_stack.1.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "18 encoder.layer_stack.1.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "19 encoder.layer_stack.1.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "20 encoder.layer_stack.1.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "21 encoder.layer_stack.1.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "22 encoder.layer_stack.1.slf_attn.layer_norm.weight torch.Size([512])\n",
      "23 encoder.layer_stack.1.slf_attn.layer_norm.bias torch.Size([512])\n",
      "24 encoder.layer_stack.1.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "25 encoder.layer_stack.1.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "26 encoder.layer_stack.1.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "27 encoder.layer_stack.1.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "28 encoder.layer_stack.1.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "29 encoder.layer_stack.1.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "30 encoder.layer_stack.1.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "31 encoder.layer_stack.1.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "32 encoder.layer_stack.2.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "33 encoder.layer_stack.2.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "34 encoder.layer_stack.2.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "35 encoder.layer_stack.2.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "36 encoder.layer_stack.2.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "37 encoder.layer_stack.2.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "38 encoder.layer_stack.2.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "39 encoder.layer_stack.2.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "40 encoder.layer_stack.2.slf_attn.layer_norm.weight torch.Size([512])\n",
      "41 encoder.layer_stack.2.slf_attn.layer_norm.bias torch.Size([512])\n",
      "42 encoder.layer_stack.2.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "43 encoder.layer_stack.2.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "44 encoder.layer_stack.2.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "45 encoder.layer_stack.2.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "46 encoder.layer_stack.2.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "47 encoder.layer_stack.2.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "48 encoder.layer_stack.2.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "49 encoder.layer_stack.2.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "50 encoder.layer_stack.3.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "51 encoder.layer_stack.3.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "52 encoder.layer_stack.3.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "53 encoder.layer_stack.3.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "54 encoder.layer_stack.3.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "55 encoder.layer_stack.3.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "56 encoder.layer_stack.3.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "57 encoder.layer_stack.3.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "58 encoder.layer_stack.3.slf_attn.layer_norm.weight torch.Size([512])\n",
      "59 encoder.layer_stack.3.slf_attn.layer_norm.bias torch.Size([512])\n",
      "60 encoder.layer_stack.3.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "61 encoder.layer_stack.3.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "62 encoder.layer_stack.3.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "63 encoder.layer_stack.3.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "64 encoder.layer_stack.3.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "65 encoder.layer_stack.3.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "66 encoder.layer_stack.3.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "67 encoder.layer_stack.3.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "68 encoder.layer_stack.4.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "69 encoder.layer_stack.4.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "70 encoder.layer_stack.4.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "71 encoder.layer_stack.4.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "72 encoder.layer_stack.4.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "73 encoder.layer_stack.4.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "74 encoder.layer_stack.4.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "75 encoder.layer_stack.4.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "76 encoder.layer_stack.4.slf_attn.layer_norm.weight torch.Size([512])\n",
      "77 encoder.layer_stack.4.slf_attn.layer_norm.bias torch.Size([512])\n",
      "78 encoder.layer_stack.4.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "79 encoder.layer_stack.4.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "80 encoder.layer_stack.4.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "81 encoder.layer_stack.4.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "82 encoder.layer_stack.4.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "83 encoder.layer_stack.4.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "84 encoder.layer_stack.4.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "85 encoder.layer_stack.4.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "86 encoder.layer_stack.5.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "87 encoder.layer_stack.5.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "88 encoder.layer_stack.5.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "89 encoder.layer_stack.5.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "90 encoder.layer_stack.5.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "91 encoder.layer_stack.5.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "92 encoder.layer_stack.5.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "93 encoder.layer_stack.5.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "94 encoder.layer_stack.5.slf_attn.layer_norm.weight torch.Size([512])\n",
      "95 encoder.layer_stack.5.slf_attn.layer_norm.bias torch.Size([512])\n",
      "96 encoder.layer_stack.5.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "97 encoder.layer_stack.5.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "98 encoder.layer_stack.5.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "99 encoder.layer_stack.5.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "100 encoder.layer_stack.5.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "101 encoder.layer_stack.5.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "102 encoder.layer_stack.5.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "103 encoder.layer_stack.5.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "104 encoder.layer_norm.weight torch.Size([512])\n",
      "105 encoder.layer_norm.bias torch.Size([512])\n",
      "106 decoder.trg_word_emb.weight torch.Size([9521, 512])\n",
      "107 decoder.position_enc.pos_table torch.Size([1, 200, 512])\n",
      "108 decoder.layer_stack.0.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "109 decoder.layer_stack.0.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "110 decoder.layer_stack.0.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "111 decoder.layer_stack.0.slf_attn.fc.weight torch.Size([512, 512])\n",
      "112 decoder.layer_stack.0.slf_attn.layer_norm.weight torch.Size([512])\n",
      "113 decoder.layer_stack.0.slf_attn.layer_norm.bias torch.Size([512])\n",
      "114 decoder.layer_stack.0.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "115 decoder.layer_stack.0.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "116 decoder.layer_stack.0.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "117 decoder.layer_stack.0.enc_attn.fc.weight torch.Size([512, 512])\n",
      "118 decoder.layer_stack.0.enc_attn.layer_norm.weight torch.Size([512])\n",
      "119 decoder.layer_stack.0.enc_attn.layer_norm.bias torch.Size([512])\n",
      "120 decoder.layer_stack.0.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "121 decoder.layer_stack.0.pos_ffn.w_1.bias torch.Size([2048])\n",
      "122 decoder.layer_stack.0.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "123 decoder.layer_stack.0.pos_ffn.w_2.bias torch.Size([512])\n",
      "124 decoder.layer_stack.0.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "125 decoder.layer_stack.0.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "126 decoder.layer_stack.1.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "127 decoder.layer_stack.1.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "128 decoder.layer_stack.1.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "129 decoder.layer_stack.1.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "130 decoder.layer_stack.1.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "131 decoder.layer_stack.1.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "132 decoder.layer_stack.1.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "133 decoder.layer_stack.1.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "134 decoder.layer_stack.1.slf_attn.layer_norm.weight torch.Size([512])\n",
      "135 decoder.layer_stack.1.slf_attn.layer_norm.bias torch.Size([512])\n",
      "136 decoder.layer_stack.1.enc_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "137 decoder.layer_stack.1.enc_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "138 decoder.layer_stack.1.enc_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "139 decoder.layer_stack.1.enc_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "140 decoder.layer_stack.1.enc_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "141 decoder.layer_stack.1.enc_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "142 decoder.layer_stack.1.enc_attn.fc_u.weight torch.Size([128, 512])\n",
      "143 decoder.layer_stack.1.enc_attn.fc_v.weight torch.Size([512, 128])\n",
      "144 decoder.layer_stack.1.enc_attn.layer_norm.weight torch.Size([512])\n",
      "145 decoder.layer_stack.1.enc_attn.layer_norm.bias torch.Size([512])\n",
      "146 decoder.layer_stack.1.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "147 decoder.layer_stack.1.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "148 decoder.layer_stack.1.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "149 decoder.layer_stack.1.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "150 decoder.layer_stack.1.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "151 decoder.layer_stack.1.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "152 decoder.layer_stack.1.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "153 decoder.layer_stack.1.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "154 decoder.layer_stack.2.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "155 decoder.layer_stack.2.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "156 decoder.layer_stack.2.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "157 decoder.layer_stack.2.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "158 decoder.layer_stack.2.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "159 decoder.layer_stack.2.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "160 decoder.layer_stack.2.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "161 decoder.layer_stack.2.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "162 decoder.layer_stack.2.slf_attn.layer_norm.weight torch.Size([512])\n",
      "163 decoder.layer_stack.2.slf_attn.layer_norm.bias torch.Size([512])\n",
      "164 decoder.layer_stack.2.enc_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "165 decoder.layer_stack.2.enc_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "166 decoder.layer_stack.2.enc_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "167 decoder.layer_stack.2.enc_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "168 decoder.layer_stack.2.enc_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "169 decoder.layer_stack.2.enc_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "170 decoder.layer_stack.2.enc_attn.fc_u.weight torch.Size([128, 512])\n",
      "171 decoder.layer_stack.2.enc_attn.fc_v.weight torch.Size([512, 128])\n",
      "172 decoder.layer_stack.2.enc_attn.layer_norm.weight torch.Size([512])\n",
      "173 decoder.layer_stack.2.enc_attn.layer_norm.bias torch.Size([512])\n",
      "174 decoder.layer_stack.2.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "175 decoder.layer_stack.2.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "176 decoder.layer_stack.2.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "177 decoder.layer_stack.2.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "178 decoder.layer_stack.2.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "179 decoder.layer_stack.2.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "180 decoder.layer_stack.2.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "181 decoder.layer_stack.2.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "182 decoder.layer_stack.3.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "183 decoder.layer_stack.3.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "184 decoder.layer_stack.3.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "185 decoder.layer_stack.3.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "186 decoder.layer_stack.3.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "187 decoder.layer_stack.3.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "188 decoder.layer_stack.3.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "189 decoder.layer_stack.3.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "190 decoder.layer_stack.3.slf_attn.layer_norm.weight torch.Size([512])\n",
      "191 decoder.layer_stack.3.slf_attn.layer_norm.bias torch.Size([512])\n",
      "192 decoder.layer_stack.3.enc_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "193 decoder.layer_stack.3.enc_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "194 decoder.layer_stack.3.enc_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "195 decoder.layer_stack.3.enc_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "196 decoder.layer_stack.3.enc_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "197 decoder.layer_stack.3.enc_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "198 decoder.layer_stack.3.enc_attn.fc_u.weight torch.Size([128, 512])\n",
      "199 decoder.layer_stack.3.enc_attn.fc_v.weight torch.Size([512, 128])\n",
      "200 decoder.layer_stack.3.enc_attn.layer_norm.weight torch.Size([512])\n",
      "201 decoder.layer_stack.3.enc_attn.layer_norm.bias torch.Size([512])\n",
      "202 decoder.layer_stack.3.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "203 decoder.layer_stack.3.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "204 decoder.layer_stack.3.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "205 decoder.layer_stack.3.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "206 decoder.layer_stack.3.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "207 decoder.layer_stack.3.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "208 decoder.layer_stack.3.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "209 decoder.layer_stack.3.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "210 decoder.layer_stack.4.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "211 decoder.layer_stack.4.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "212 decoder.layer_stack.4.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "213 decoder.layer_stack.4.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "214 decoder.layer_stack.4.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "215 decoder.layer_stack.4.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "216 decoder.layer_stack.4.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "217 decoder.layer_stack.4.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "218 decoder.layer_stack.4.slf_attn.layer_norm.weight torch.Size([512])\n",
      "219 decoder.layer_stack.4.slf_attn.layer_norm.bias torch.Size([512])\n",
      "220 decoder.layer_stack.4.enc_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "221 decoder.layer_stack.4.enc_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "222 decoder.layer_stack.4.enc_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "223 decoder.layer_stack.4.enc_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "224 decoder.layer_stack.4.enc_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "225 decoder.layer_stack.4.enc_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "226 decoder.layer_stack.4.enc_attn.fc_u.weight torch.Size([128, 512])\n",
      "227 decoder.layer_stack.4.enc_attn.fc_v.weight torch.Size([512, 128])\n",
      "228 decoder.layer_stack.4.enc_attn.layer_norm.weight torch.Size([512])\n",
      "229 decoder.layer_stack.4.enc_attn.layer_norm.bias torch.Size([512])\n",
      "230 decoder.layer_stack.4.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "231 decoder.layer_stack.4.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "232 decoder.layer_stack.4.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "233 decoder.layer_stack.4.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "234 decoder.layer_stack.4.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "235 decoder.layer_stack.4.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "236 decoder.layer_stack.4.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "237 decoder.layer_stack.4.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "238 decoder.layer_stack.5.slf_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "239 decoder.layer_stack.5.slf_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "240 decoder.layer_stack.5.slf_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "241 decoder.layer_stack.5.slf_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "242 decoder.layer_stack.5.slf_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "243 decoder.layer_stack.5.slf_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "244 decoder.layer_stack.5.slf_attn.fc_u.weight torch.Size([128, 512])\n",
      "245 decoder.layer_stack.5.slf_attn.fc_v.weight torch.Size([512, 128])\n",
      "246 decoder.layer_stack.5.slf_attn.layer_norm.weight torch.Size([512])\n",
      "247 decoder.layer_stack.5.slf_attn.layer_norm.bias torch.Size([512])\n",
      "248 decoder.layer_stack.5.enc_attn.w_qs_u.weight torch.Size([128, 512])\n",
      "249 decoder.layer_stack.5.enc_attn.w_qs_v.weight torch.Size([512, 128])\n",
      "250 decoder.layer_stack.5.enc_attn.w_ks_u.weight torch.Size([128, 512])\n",
      "251 decoder.layer_stack.5.enc_attn.w_ks_v.weight torch.Size([512, 128])\n",
      "252 decoder.layer_stack.5.enc_attn.w_vs_u.weight torch.Size([128, 512])\n",
      "253 decoder.layer_stack.5.enc_attn.w_vs_v.weight torch.Size([512, 128])\n",
      "254 decoder.layer_stack.5.enc_attn.fc_u.weight torch.Size([128, 512])\n",
      "255 decoder.layer_stack.5.enc_attn.fc_v.weight torch.Size([512, 128])\n",
      "256 decoder.layer_stack.5.enc_attn.layer_norm.weight torch.Size([512])\n",
      "257 decoder.layer_stack.5.enc_attn.layer_norm.bias torch.Size([512])\n",
      "258 decoder.layer_stack.5.pos_ffn.w_1_u.weight torch.Size([128, 512])\n",
      "259 decoder.layer_stack.5.pos_ffn.w_1_v.weight torch.Size([2048, 128])\n",
      "260 decoder.layer_stack.5.pos_ffn.w_1_v.bias torch.Size([2048])\n",
      "261 decoder.layer_stack.5.pos_ffn.w_2_u.weight torch.Size([128, 2048])\n",
      "262 decoder.layer_stack.5.pos_ffn.w_2_v.weight torch.Size([512, 128])\n",
      "263 decoder.layer_stack.5.pos_ffn.w_2_v.bias torch.Size([512])\n",
      "264 decoder.layer_stack.5.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "265 decoder.layer_stack.5.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "266 decoder.layer_norm.weight torch.Size([512])\n",
      "267 decoder.layer_norm.bias torch.Size([512])\n",
      "268 trg_word_prj.weight torch.Size([9521, 512])\n"
     ]
    }
   ],
   "source": [
    "for param_index, (param_name, param) in enumerate(lr_transformer.state_dict().items()):\n",
    "    print(param_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    opt_src_vocab_size,\n",
    "    opt_trg_vocab_size,\n",
    "    src_pad_idx=opt_src_pad_idx,\n",
    "    trg_pad_idx=opt_trg_pad_idx,\n",
    "    trg_emb_prj_weight_sharing=opt_proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=opt_embs_share_weight,\n",
    "    d_k=opt_d_k,\n",
    "    d_v=opt_d_v,\n",
    "    d_model=opt_d_model,\n",
    "    d_word_vec=opt_d_word_vec,\n",
    "    d_inner=opt_d_inner_hid,\n",
    "    n_layers=opt_n_layers,\n",
    "    n_head=opt_n_head,\n",
    "    dropout=opt_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 encoder.src_word_emb.weight torch.Size([9521, 512])\n",
      "1 encoder.position_enc.pos_table torch.Size([1, 200, 512])\n",
      "2 encoder.layer_stack.0.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "3 encoder.layer_stack.0.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "4 encoder.layer_stack.0.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "5 encoder.layer_stack.0.slf_attn.fc.weight torch.Size([512, 512])\n",
      "6 encoder.layer_stack.0.slf_attn.layer_norm.weight torch.Size([512])\n",
      "7 encoder.layer_stack.0.slf_attn.layer_norm.bias torch.Size([512])\n",
      "8 encoder.layer_stack.0.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "9 encoder.layer_stack.0.pos_ffn.w_1.bias torch.Size([2048])\n",
      "10 encoder.layer_stack.0.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "11 encoder.layer_stack.0.pos_ffn.w_2.bias torch.Size([512])\n",
      "12 encoder.layer_stack.0.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "13 encoder.layer_stack.0.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "14 encoder.layer_stack.1.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "15 encoder.layer_stack.1.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "16 encoder.layer_stack.1.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "17 encoder.layer_stack.1.slf_attn.fc.weight torch.Size([512, 512])\n",
      "18 encoder.layer_stack.1.slf_attn.layer_norm.weight torch.Size([512])\n",
      "19 encoder.layer_stack.1.slf_attn.layer_norm.bias torch.Size([512])\n",
      "20 encoder.layer_stack.1.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "21 encoder.layer_stack.1.pos_ffn.w_1.bias torch.Size([2048])\n",
      "22 encoder.layer_stack.1.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "23 encoder.layer_stack.1.pos_ffn.w_2.bias torch.Size([512])\n",
      "24 encoder.layer_stack.1.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "25 encoder.layer_stack.1.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "26 encoder.layer_stack.2.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "27 encoder.layer_stack.2.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "28 encoder.layer_stack.2.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "29 encoder.layer_stack.2.slf_attn.fc.weight torch.Size([512, 512])\n",
      "30 encoder.layer_stack.2.slf_attn.layer_norm.weight torch.Size([512])\n",
      "31 encoder.layer_stack.2.slf_attn.layer_norm.bias torch.Size([512])\n",
      "32 encoder.layer_stack.2.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "33 encoder.layer_stack.2.pos_ffn.w_1.bias torch.Size([2048])\n",
      "34 encoder.layer_stack.2.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "35 encoder.layer_stack.2.pos_ffn.w_2.bias torch.Size([512])\n",
      "36 encoder.layer_stack.2.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "37 encoder.layer_stack.2.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "38 encoder.layer_stack.3.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "39 encoder.layer_stack.3.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "40 encoder.layer_stack.3.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "41 encoder.layer_stack.3.slf_attn.fc.weight torch.Size([512, 512])\n",
      "42 encoder.layer_stack.3.slf_attn.layer_norm.weight torch.Size([512])\n",
      "43 encoder.layer_stack.3.slf_attn.layer_norm.bias torch.Size([512])\n",
      "44 encoder.layer_stack.3.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "45 encoder.layer_stack.3.pos_ffn.w_1.bias torch.Size([2048])\n",
      "46 encoder.layer_stack.3.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "47 encoder.layer_stack.3.pos_ffn.w_2.bias torch.Size([512])\n",
      "48 encoder.layer_stack.3.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "49 encoder.layer_stack.3.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "50 encoder.layer_stack.4.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "51 encoder.layer_stack.4.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "52 encoder.layer_stack.4.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "53 encoder.layer_stack.4.slf_attn.fc.weight torch.Size([512, 512])\n",
      "54 encoder.layer_stack.4.slf_attn.layer_norm.weight torch.Size([512])\n",
      "55 encoder.layer_stack.4.slf_attn.layer_norm.bias torch.Size([512])\n",
      "56 encoder.layer_stack.4.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "57 encoder.layer_stack.4.pos_ffn.w_1.bias torch.Size([2048])\n",
      "58 encoder.layer_stack.4.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "59 encoder.layer_stack.4.pos_ffn.w_2.bias torch.Size([512])\n",
      "60 encoder.layer_stack.4.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "61 encoder.layer_stack.4.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "62 encoder.layer_stack.5.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "63 encoder.layer_stack.5.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "64 encoder.layer_stack.5.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "65 encoder.layer_stack.5.slf_attn.fc.weight torch.Size([512, 512])\n",
      "66 encoder.layer_stack.5.slf_attn.layer_norm.weight torch.Size([512])\n",
      "67 encoder.layer_stack.5.slf_attn.layer_norm.bias torch.Size([512])\n",
      "68 encoder.layer_stack.5.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "69 encoder.layer_stack.5.pos_ffn.w_1.bias torch.Size([2048])\n",
      "70 encoder.layer_stack.5.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "71 encoder.layer_stack.5.pos_ffn.w_2.bias torch.Size([512])\n",
      "72 encoder.layer_stack.5.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "73 encoder.layer_stack.5.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "74 encoder.layer_norm.weight torch.Size([512])\n",
      "75 encoder.layer_norm.bias torch.Size([512])\n",
      "76 decoder.trg_word_emb.weight torch.Size([9521, 512])\n",
      "77 decoder.position_enc.pos_table torch.Size([1, 200, 512])\n",
      "78 decoder.layer_stack.0.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "79 decoder.layer_stack.0.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "80 decoder.layer_stack.0.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "81 decoder.layer_stack.0.slf_attn.fc.weight torch.Size([512, 512])\n",
      "82 decoder.layer_stack.0.slf_attn.layer_norm.weight torch.Size([512])\n",
      "83 decoder.layer_stack.0.slf_attn.layer_norm.bias torch.Size([512])\n",
      "84 decoder.layer_stack.0.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "85 decoder.layer_stack.0.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "86 decoder.layer_stack.0.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "87 decoder.layer_stack.0.enc_attn.fc.weight torch.Size([512, 512])\n",
      "88 decoder.layer_stack.0.enc_attn.layer_norm.weight torch.Size([512])\n",
      "89 decoder.layer_stack.0.enc_attn.layer_norm.bias torch.Size([512])\n",
      "90 decoder.layer_stack.0.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "91 decoder.layer_stack.0.pos_ffn.w_1.bias torch.Size([2048])\n",
      "92 decoder.layer_stack.0.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "93 decoder.layer_stack.0.pos_ffn.w_2.bias torch.Size([512])\n",
      "94 decoder.layer_stack.0.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "95 decoder.layer_stack.0.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "96 decoder.layer_stack.1.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "97 decoder.layer_stack.1.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "98 decoder.layer_stack.1.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "99 decoder.layer_stack.1.slf_attn.fc.weight torch.Size([512, 512])\n",
      "100 decoder.layer_stack.1.slf_attn.layer_norm.weight torch.Size([512])\n",
      "101 decoder.layer_stack.1.slf_attn.layer_norm.bias torch.Size([512])\n",
      "102 decoder.layer_stack.1.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "103 decoder.layer_stack.1.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "104 decoder.layer_stack.1.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "105 decoder.layer_stack.1.enc_attn.fc.weight torch.Size([512, 512])\n",
      "106 decoder.layer_stack.1.enc_attn.layer_norm.weight torch.Size([512])\n",
      "107 decoder.layer_stack.1.enc_attn.layer_norm.bias torch.Size([512])\n",
      "108 decoder.layer_stack.1.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "109 decoder.layer_stack.1.pos_ffn.w_1.bias torch.Size([2048])\n",
      "110 decoder.layer_stack.1.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "111 decoder.layer_stack.1.pos_ffn.w_2.bias torch.Size([512])\n",
      "112 decoder.layer_stack.1.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "113 decoder.layer_stack.1.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "114 decoder.layer_stack.2.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "115 decoder.layer_stack.2.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "116 decoder.layer_stack.2.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "117 decoder.layer_stack.2.slf_attn.fc.weight torch.Size([512, 512])\n",
      "118 decoder.layer_stack.2.slf_attn.layer_norm.weight torch.Size([512])\n",
      "119 decoder.layer_stack.2.slf_attn.layer_norm.bias torch.Size([512])\n",
      "120 decoder.layer_stack.2.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "121 decoder.layer_stack.2.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "122 decoder.layer_stack.2.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "123 decoder.layer_stack.2.enc_attn.fc.weight torch.Size([512, 512])\n",
      "124 decoder.layer_stack.2.enc_attn.layer_norm.weight torch.Size([512])\n",
      "125 decoder.layer_stack.2.enc_attn.layer_norm.bias torch.Size([512])\n",
      "126 decoder.layer_stack.2.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "127 decoder.layer_stack.2.pos_ffn.w_1.bias torch.Size([2048])\n",
      "128 decoder.layer_stack.2.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "129 decoder.layer_stack.2.pos_ffn.w_2.bias torch.Size([512])\n",
      "130 decoder.layer_stack.2.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "131 decoder.layer_stack.2.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "132 decoder.layer_stack.3.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "133 decoder.layer_stack.3.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "134 decoder.layer_stack.3.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "135 decoder.layer_stack.3.slf_attn.fc.weight torch.Size([512, 512])\n",
      "136 decoder.layer_stack.3.slf_attn.layer_norm.weight torch.Size([512])\n",
      "137 decoder.layer_stack.3.slf_attn.layer_norm.bias torch.Size([512])\n",
      "138 decoder.layer_stack.3.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "139 decoder.layer_stack.3.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "140 decoder.layer_stack.3.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "141 decoder.layer_stack.3.enc_attn.fc.weight torch.Size([512, 512])\n",
      "142 decoder.layer_stack.3.enc_attn.layer_norm.weight torch.Size([512])\n",
      "143 decoder.layer_stack.3.enc_attn.layer_norm.bias torch.Size([512])\n",
      "144 decoder.layer_stack.3.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "145 decoder.layer_stack.3.pos_ffn.w_1.bias torch.Size([2048])\n",
      "146 decoder.layer_stack.3.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "147 decoder.layer_stack.3.pos_ffn.w_2.bias torch.Size([512])\n",
      "148 decoder.layer_stack.3.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "149 decoder.layer_stack.3.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "150 decoder.layer_stack.4.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "151 decoder.layer_stack.4.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "152 decoder.layer_stack.4.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "153 decoder.layer_stack.4.slf_attn.fc.weight torch.Size([512, 512])\n",
      "154 decoder.layer_stack.4.slf_attn.layer_norm.weight torch.Size([512])\n",
      "155 decoder.layer_stack.4.slf_attn.layer_norm.bias torch.Size([512])\n",
      "156 decoder.layer_stack.4.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "157 decoder.layer_stack.4.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "158 decoder.layer_stack.4.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "159 decoder.layer_stack.4.enc_attn.fc.weight torch.Size([512, 512])\n",
      "160 decoder.layer_stack.4.enc_attn.layer_norm.weight torch.Size([512])\n",
      "161 decoder.layer_stack.4.enc_attn.layer_norm.bias torch.Size([512])\n",
      "162 decoder.layer_stack.4.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "163 decoder.layer_stack.4.pos_ffn.w_1.bias torch.Size([2048])\n",
      "164 decoder.layer_stack.4.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "165 decoder.layer_stack.4.pos_ffn.w_2.bias torch.Size([512])\n",
      "166 decoder.layer_stack.4.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "167 decoder.layer_stack.4.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "168 decoder.layer_stack.5.slf_attn.w_qs.weight torch.Size([512, 512])\n",
      "169 decoder.layer_stack.5.slf_attn.w_ks.weight torch.Size([512, 512])\n",
      "170 decoder.layer_stack.5.slf_attn.w_vs.weight torch.Size([512, 512])\n",
      "171 decoder.layer_stack.5.slf_attn.fc.weight torch.Size([512, 512])\n",
      "172 decoder.layer_stack.5.slf_attn.layer_norm.weight torch.Size([512])\n",
      "173 decoder.layer_stack.5.slf_attn.layer_norm.bias torch.Size([512])\n",
      "174 decoder.layer_stack.5.enc_attn.w_qs.weight torch.Size([512, 512])\n",
      "175 decoder.layer_stack.5.enc_attn.w_ks.weight torch.Size([512, 512])\n",
      "176 decoder.layer_stack.5.enc_attn.w_vs.weight torch.Size([512, 512])\n",
      "177 decoder.layer_stack.5.enc_attn.fc.weight torch.Size([512, 512])\n",
      "178 decoder.layer_stack.5.enc_attn.layer_norm.weight torch.Size([512])\n",
      "179 decoder.layer_stack.5.enc_attn.layer_norm.bias torch.Size([512])\n",
      "180 decoder.layer_stack.5.pos_ffn.w_1.weight torch.Size([2048, 512])\n",
      "181 decoder.layer_stack.5.pos_ffn.w_1.bias torch.Size([2048])\n",
      "182 decoder.layer_stack.5.pos_ffn.w_2.weight torch.Size([512, 2048])\n",
      "183 decoder.layer_stack.5.pos_ffn.w_2.bias torch.Size([512])\n",
      "184 decoder.layer_stack.5.pos_ffn.layer_norm.weight torch.Size([512])\n",
      "185 decoder.layer_stack.5.pos_ffn.layer_norm.bias torch.Size([512])\n",
      "186 decoder.layer_norm.weight torch.Size([512])\n",
      "187 decoder.layer_norm.bias torch.Size([512])\n",
      "188 trg_word_prj.weight torch.Size([9521, 512])\n"
     ]
    }
   ],
   "source": [
    "for param_index, (param_name, param) in enumerate(transformer.state_dict().items()):\n",
    "    print(param_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_vanilla_model(vanilla_model, low_rank_model, rank_ratio=0.25):\n",
    "    collected_weights = []\n",
    "    for p_index, (name, param) in enumerate(vanilla_model.state_dict().items()):\n",
    "        if len(param.size()) == 2 and p_index not in range(0, 14) and p_index not in range(76, 96) and p_index != 188:\n",
    "            rank = min(param.size()[0], param.size()[1])\n",
    "            sliced_rank = int(rank * rank_ratio)\n",
    "            u, s, v = torch.svd(param)\n",
    "            u_weight = u * torch.sqrt(s)\n",
    "            v_weight = torch.sqrt(s) * v\n",
    "            u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "            #collected_weights.append(u_weight_sliced)\n",
    "            collected_weights.append(v_weight_sliced.t())\n",
    "            collected_weights.append(u_weight_sliced)\n",
    "        else:\n",
    "            collected_weights.append(param)\n",
    "            \n",
    "    #for cw_index, cw in enumerate(collected_weights):\n",
    "    #     print(\"cw_index: {}, cw: {}\".format(cw_index, cw.size()))\n",
    "         \n",
    "    reconstructed_state_dict = {}\n",
    "    model_counter = 0\n",
    "    for p_index, (name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "        #print(\"p_index: {}, name: {}, param size: {}, collected weight size: {}\".format(p_index,\n",
    "        #                                                                                name,\n",
    "        #                                                                                param.size(), collected_weights[model_counter].size()))\n",
    "        assert param.size() == collected_weights[model_counter].size()\n",
    "        reconstructed_state_dict[name] = collected_weights[model_counter]\n",
    "        model_counter += 1\n",
    "    low_rank_model.load_state_dict(reconstructed_state_dict)\n",
    "    return low_rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 512])\n",
      "dist: 0.0017176233232021332\n",
      "u size: torch.Size([2048, 512]), s size: torch.Size([512]), v size: torch.Size([512, 512])\n",
      "u weight slided: torch.Size([2048, 128]), v weight sliced: torch.Size([512, 128])\n",
      "dist approx: 775.8424682617188\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2048, 512)\n",
    "print(a.size())\n",
    "rank = min(a.size()[0], a.size()[1])\n",
    "sliced_rank = int(rank * 0.25)\n",
    "u, s, v = torch.svd(a)\n",
    "print(\"dist: {}\".format(torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))))\n",
    "print(\"u size: {}, s size: {}, v size: {}\".format(u.size(), s.size(), v.size()))\n",
    "u_weight = u * torch.sqrt(s)\n",
    "v_weight = torch.sqrt(s) * v\n",
    "u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "print(\"u weight slided: {}, v weight sliced: {}\".format(u_weight_sliced.size(), v_weight_sliced.size()))\n",
    "print(\"dist approx: {}\".format(torch.dist(a, torch.mm(u_weight_sliced, v_weight_sliced.t()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw_index: 0, cw: torch.Size([9521, 512])\n",
      "cw_index: 1, cw: torch.Size([1, 200, 512])\n",
      "cw_index: 2, cw: torch.Size([512, 512])\n",
      "cw_index: 3, cw: torch.Size([512, 512])\n",
      "cw_index: 4, cw: torch.Size([512, 512])\n",
      "cw_index: 5, cw: torch.Size([512, 512])\n",
      "cw_index: 6, cw: torch.Size([512])\n",
      "cw_index: 7, cw: torch.Size([512])\n",
      "cw_index: 8, cw: torch.Size([2048, 512])\n",
      "cw_index: 9, cw: torch.Size([2048])\n",
      "cw_index: 10, cw: torch.Size([512, 2048])\n",
      "cw_index: 11, cw: torch.Size([512])\n",
      "cw_index: 12, cw: torch.Size([512])\n",
      "cw_index: 13, cw: torch.Size([512])\n",
      "cw_index: 14, cw: torch.Size([128, 512])\n",
      "cw_index: 15, cw: torch.Size([512, 128])\n",
      "cw_index: 16, cw: torch.Size([128, 512])\n",
      "cw_index: 17, cw: torch.Size([512, 128])\n",
      "cw_index: 18, cw: torch.Size([128, 512])\n",
      "cw_index: 19, cw: torch.Size([512, 128])\n",
      "cw_index: 20, cw: torch.Size([128, 512])\n",
      "cw_index: 21, cw: torch.Size([512, 128])\n",
      "cw_index: 22, cw: torch.Size([512])\n",
      "cw_index: 23, cw: torch.Size([512])\n",
      "cw_index: 24, cw: torch.Size([128, 512])\n",
      "cw_index: 25, cw: torch.Size([2048, 128])\n",
      "cw_index: 26, cw: torch.Size([2048])\n",
      "cw_index: 27, cw: torch.Size([128, 2048])\n",
      "cw_index: 28, cw: torch.Size([512, 128])\n",
      "cw_index: 29, cw: torch.Size([512])\n",
      "cw_index: 30, cw: torch.Size([512])\n",
      "cw_index: 31, cw: torch.Size([512])\n",
      "cw_index: 32, cw: torch.Size([128, 512])\n",
      "cw_index: 33, cw: torch.Size([512, 128])\n",
      "cw_index: 34, cw: torch.Size([128, 512])\n",
      "cw_index: 35, cw: torch.Size([512, 128])\n",
      "cw_index: 36, cw: torch.Size([128, 512])\n",
      "cw_index: 37, cw: torch.Size([512, 128])\n",
      "cw_index: 38, cw: torch.Size([128, 512])\n",
      "cw_index: 39, cw: torch.Size([512, 128])\n",
      "cw_index: 40, cw: torch.Size([512])\n",
      "cw_index: 41, cw: torch.Size([512])\n",
      "cw_index: 42, cw: torch.Size([128, 512])\n",
      "cw_index: 43, cw: torch.Size([2048, 128])\n",
      "cw_index: 44, cw: torch.Size([2048])\n",
      "cw_index: 45, cw: torch.Size([128, 2048])\n",
      "cw_index: 46, cw: torch.Size([512, 128])\n",
      "cw_index: 47, cw: torch.Size([512])\n",
      "cw_index: 48, cw: torch.Size([512])\n",
      "cw_index: 49, cw: torch.Size([512])\n",
      "cw_index: 50, cw: torch.Size([128, 512])\n",
      "cw_index: 51, cw: torch.Size([512, 128])\n",
      "cw_index: 52, cw: torch.Size([128, 512])\n",
      "cw_index: 53, cw: torch.Size([512, 128])\n",
      "cw_index: 54, cw: torch.Size([128, 512])\n",
      "cw_index: 55, cw: torch.Size([512, 128])\n",
      "cw_index: 56, cw: torch.Size([128, 512])\n",
      "cw_index: 57, cw: torch.Size([512, 128])\n",
      "cw_index: 58, cw: torch.Size([512])\n",
      "cw_index: 59, cw: torch.Size([512])\n",
      "cw_index: 60, cw: torch.Size([128, 512])\n",
      "cw_index: 61, cw: torch.Size([2048, 128])\n",
      "cw_index: 62, cw: torch.Size([2048])\n",
      "cw_index: 63, cw: torch.Size([128, 2048])\n",
      "cw_index: 64, cw: torch.Size([512, 128])\n",
      "cw_index: 65, cw: torch.Size([512])\n",
      "cw_index: 66, cw: torch.Size([512])\n",
      "cw_index: 67, cw: torch.Size([512])\n",
      "cw_index: 68, cw: torch.Size([128, 512])\n",
      "cw_index: 69, cw: torch.Size([512, 128])\n",
      "cw_index: 70, cw: torch.Size([128, 512])\n",
      "cw_index: 71, cw: torch.Size([512, 128])\n",
      "cw_index: 72, cw: torch.Size([128, 512])\n",
      "cw_index: 73, cw: torch.Size([512, 128])\n",
      "cw_index: 74, cw: torch.Size([128, 512])\n",
      "cw_index: 75, cw: torch.Size([512, 128])\n",
      "cw_index: 76, cw: torch.Size([512])\n",
      "cw_index: 77, cw: torch.Size([512])\n",
      "cw_index: 78, cw: torch.Size([128, 512])\n",
      "cw_index: 79, cw: torch.Size([2048, 128])\n",
      "cw_index: 80, cw: torch.Size([2048])\n",
      "cw_index: 81, cw: torch.Size([128, 2048])\n",
      "cw_index: 82, cw: torch.Size([512, 128])\n",
      "cw_index: 83, cw: torch.Size([512])\n",
      "cw_index: 84, cw: torch.Size([512])\n",
      "cw_index: 85, cw: torch.Size([512])\n",
      "cw_index: 86, cw: torch.Size([128, 512])\n",
      "cw_index: 87, cw: torch.Size([512, 128])\n",
      "cw_index: 88, cw: torch.Size([128, 512])\n",
      "cw_index: 89, cw: torch.Size([512, 128])\n",
      "cw_index: 90, cw: torch.Size([128, 512])\n",
      "cw_index: 91, cw: torch.Size([512, 128])\n",
      "cw_index: 92, cw: torch.Size([128, 512])\n",
      "cw_index: 93, cw: torch.Size([512, 128])\n",
      "cw_index: 94, cw: torch.Size([512])\n",
      "cw_index: 95, cw: torch.Size([512])\n",
      "cw_index: 96, cw: torch.Size([128, 512])\n",
      "cw_index: 97, cw: torch.Size([2048, 128])\n",
      "cw_index: 98, cw: torch.Size([2048])\n",
      "cw_index: 99, cw: torch.Size([128, 2048])\n",
      "cw_index: 100, cw: torch.Size([512, 128])\n",
      "cw_index: 101, cw: torch.Size([512])\n",
      "cw_index: 102, cw: torch.Size([512])\n",
      "cw_index: 103, cw: torch.Size([512])\n",
      "cw_index: 104, cw: torch.Size([512])\n",
      "cw_index: 105, cw: torch.Size([512])\n",
      "cw_index: 106, cw: torch.Size([9521, 512])\n",
      "cw_index: 107, cw: torch.Size([1, 200, 512])\n",
      "cw_index: 108, cw: torch.Size([512, 512])\n",
      "cw_index: 109, cw: torch.Size([512, 512])\n",
      "cw_index: 110, cw: torch.Size([512, 512])\n",
      "cw_index: 111, cw: torch.Size([512, 512])\n",
      "cw_index: 112, cw: torch.Size([512])\n",
      "cw_index: 113, cw: torch.Size([512])\n",
      "cw_index: 114, cw: torch.Size([512, 512])\n",
      "cw_index: 115, cw: torch.Size([512, 512])\n",
      "cw_index: 116, cw: torch.Size([512, 512])\n",
      "cw_index: 117, cw: torch.Size([512, 512])\n",
      "cw_index: 118, cw: torch.Size([512])\n",
      "cw_index: 119, cw: torch.Size([512])\n",
      "cw_index: 120, cw: torch.Size([2048, 512])\n",
      "cw_index: 121, cw: torch.Size([2048])\n",
      "cw_index: 122, cw: torch.Size([512, 2048])\n",
      "cw_index: 123, cw: torch.Size([512])\n",
      "cw_index: 124, cw: torch.Size([512])\n",
      "cw_index: 125, cw: torch.Size([512])\n",
      "cw_index: 126, cw: torch.Size([128, 512])\n",
      "cw_index: 127, cw: torch.Size([512, 128])\n",
      "cw_index: 128, cw: torch.Size([128, 512])\n",
      "cw_index: 129, cw: torch.Size([512, 128])\n",
      "cw_index: 130, cw: torch.Size([128, 512])\n",
      "cw_index: 131, cw: torch.Size([512, 128])\n",
      "cw_index: 132, cw: torch.Size([128, 512])\n",
      "cw_index: 133, cw: torch.Size([512, 128])\n",
      "cw_index: 134, cw: torch.Size([512])\n",
      "cw_index: 135, cw: torch.Size([512])\n",
      "cw_index: 136, cw: torch.Size([128, 512])\n",
      "cw_index: 137, cw: torch.Size([512, 128])\n",
      "cw_index: 138, cw: torch.Size([128, 512])\n",
      "cw_index: 139, cw: torch.Size([512, 128])\n",
      "cw_index: 140, cw: torch.Size([128, 512])\n",
      "cw_index: 141, cw: torch.Size([512, 128])\n",
      "cw_index: 142, cw: torch.Size([128, 512])\n",
      "cw_index: 143, cw: torch.Size([512, 128])\n",
      "cw_index: 144, cw: torch.Size([512])\n",
      "cw_index: 145, cw: torch.Size([512])\n",
      "cw_index: 146, cw: torch.Size([128, 512])\n",
      "cw_index: 147, cw: torch.Size([2048, 128])\n",
      "cw_index: 148, cw: torch.Size([2048])\n",
      "cw_index: 149, cw: torch.Size([128, 2048])\n",
      "cw_index: 150, cw: torch.Size([512, 128])\n",
      "cw_index: 151, cw: torch.Size([512])\n",
      "cw_index: 152, cw: torch.Size([512])\n",
      "cw_index: 153, cw: torch.Size([512])\n",
      "cw_index: 154, cw: torch.Size([128, 512])\n",
      "cw_index: 155, cw: torch.Size([512, 128])\n",
      "cw_index: 156, cw: torch.Size([128, 512])\n",
      "cw_index: 157, cw: torch.Size([512, 128])\n",
      "cw_index: 158, cw: torch.Size([128, 512])\n",
      "cw_index: 159, cw: torch.Size([512, 128])\n",
      "cw_index: 160, cw: torch.Size([128, 512])\n",
      "cw_index: 161, cw: torch.Size([512, 128])\n",
      "cw_index: 162, cw: torch.Size([512])\n",
      "cw_index: 163, cw: torch.Size([512])\n",
      "cw_index: 164, cw: torch.Size([128, 512])\n",
      "cw_index: 165, cw: torch.Size([512, 128])\n",
      "cw_index: 166, cw: torch.Size([128, 512])\n",
      "cw_index: 167, cw: torch.Size([512, 128])\n",
      "cw_index: 168, cw: torch.Size([128, 512])\n",
      "cw_index: 169, cw: torch.Size([512, 128])\n",
      "cw_index: 170, cw: torch.Size([128, 512])\n",
      "cw_index: 171, cw: torch.Size([512, 128])\n",
      "cw_index: 172, cw: torch.Size([512])\n",
      "cw_index: 173, cw: torch.Size([512])\n",
      "cw_index: 174, cw: torch.Size([128, 512])\n",
      "cw_index: 175, cw: torch.Size([2048, 128])\n",
      "cw_index: 176, cw: torch.Size([2048])\n",
      "cw_index: 177, cw: torch.Size([128, 2048])\n",
      "cw_index: 178, cw: torch.Size([512, 128])\n",
      "cw_index: 179, cw: torch.Size([512])\n",
      "cw_index: 180, cw: torch.Size([512])\n",
      "cw_index: 181, cw: torch.Size([512])\n",
      "cw_index: 182, cw: torch.Size([128, 512])\n",
      "cw_index: 183, cw: torch.Size([512, 128])\n",
      "cw_index: 184, cw: torch.Size([128, 512])\n",
      "cw_index: 185, cw: torch.Size([512, 128])\n",
      "cw_index: 186, cw: torch.Size([128, 512])\n",
      "cw_index: 187, cw: torch.Size([512, 128])\n",
      "cw_index: 188, cw: torch.Size([128, 512])\n",
      "cw_index: 189, cw: torch.Size([512, 128])\n",
      "cw_index: 190, cw: torch.Size([512])\n",
      "cw_index: 191, cw: torch.Size([512])\n",
      "cw_index: 192, cw: torch.Size([128, 512])\n",
      "cw_index: 193, cw: torch.Size([512, 128])\n",
      "cw_index: 194, cw: torch.Size([128, 512])\n",
      "cw_index: 195, cw: torch.Size([512, 128])\n",
      "cw_index: 196, cw: torch.Size([128, 512])\n",
      "cw_index: 197, cw: torch.Size([512, 128])\n",
      "cw_index: 198, cw: torch.Size([128, 512])\n",
      "cw_index: 199, cw: torch.Size([512, 128])\n",
      "cw_index: 200, cw: torch.Size([512])\n",
      "cw_index: 201, cw: torch.Size([512])\n",
      "cw_index: 202, cw: torch.Size([128, 512])\n",
      "cw_index: 203, cw: torch.Size([2048, 128])\n",
      "cw_index: 204, cw: torch.Size([2048])\n",
      "cw_index: 205, cw: torch.Size([128, 2048])\n",
      "cw_index: 206, cw: torch.Size([512, 128])\n",
      "cw_index: 207, cw: torch.Size([512])\n",
      "cw_index: 208, cw: torch.Size([512])\n",
      "cw_index: 209, cw: torch.Size([512])\n",
      "cw_index: 210, cw: torch.Size([128, 512])\n",
      "cw_index: 211, cw: torch.Size([512, 128])\n",
      "cw_index: 212, cw: torch.Size([128, 512])\n",
      "cw_index: 213, cw: torch.Size([512, 128])\n",
      "cw_index: 214, cw: torch.Size([128, 512])\n",
      "cw_index: 215, cw: torch.Size([512, 128])\n",
      "cw_index: 216, cw: torch.Size([128, 512])\n",
      "cw_index: 217, cw: torch.Size([512, 128])\n",
      "cw_index: 218, cw: torch.Size([512])\n",
      "cw_index: 219, cw: torch.Size([512])\n",
      "cw_index: 220, cw: torch.Size([128, 512])\n",
      "cw_index: 221, cw: torch.Size([512, 128])\n",
      "cw_index: 222, cw: torch.Size([128, 512])\n",
      "cw_index: 223, cw: torch.Size([512, 128])\n",
      "cw_index: 224, cw: torch.Size([128, 512])\n",
      "cw_index: 225, cw: torch.Size([512, 128])\n",
      "cw_index: 226, cw: torch.Size([128, 512])\n",
      "cw_index: 227, cw: torch.Size([512, 128])\n",
      "cw_index: 228, cw: torch.Size([512])\n",
      "cw_index: 229, cw: torch.Size([512])\n",
      "cw_index: 230, cw: torch.Size([128, 512])\n",
      "cw_index: 231, cw: torch.Size([2048, 128])\n",
      "cw_index: 232, cw: torch.Size([2048])\n",
      "cw_index: 233, cw: torch.Size([128, 2048])\n",
      "cw_index: 234, cw: torch.Size([512, 128])\n",
      "cw_index: 235, cw: torch.Size([512])\n",
      "cw_index: 236, cw: torch.Size([512])\n",
      "cw_index: 237, cw: torch.Size([512])\n",
      "cw_index: 238, cw: torch.Size([128, 512])\n",
      "cw_index: 239, cw: torch.Size([512, 128])\n",
      "cw_index: 240, cw: torch.Size([128, 512])\n",
      "cw_index: 241, cw: torch.Size([512, 128])\n",
      "cw_index: 242, cw: torch.Size([128, 512])\n",
      "cw_index: 243, cw: torch.Size([512, 128])\n",
      "cw_index: 244, cw: torch.Size([128, 512])\n",
      "cw_index: 245, cw: torch.Size([512, 128])\n",
      "cw_index: 246, cw: torch.Size([512])\n",
      "cw_index: 247, cw: torch.Size([512])\n",
      "cw_index: 248, cw: torch.Size([128, 512])\n",
      "cw_index: 249, cw: torch.Size([512, 128])\n",
      "cw_index: 250, cw: torch.Size([128, 512])\n",
      "cw_index: 251, cw: torch.Size([512, 128])\n",
      "cw_index: 252, cw: torch.Size([128, 512])\n",
      "cw_index: 253, cw: torch.Size([512, 128])\n",
      "cw_index: 254, cw: torch.Size([128, 512])\n",
      "cw_index: 255, cw: torch.Size([512, 128])\n",
      "cw_index: 256, cw: torch.Size([512])\n",
      "cw_index: 257, cw: torch.Size([512])\n",
      "cw_index: 258, cw: torch.Size([128, 512])\n",
      "cw_index: 259, cw: torch.Size([2048, 128])\n",
      "cw_index: 260, cw: torch.Size([2048])\n",
      "cw_index: 261, cw: torch.Size([128, 2048])\n",
      "cw_index: 262, cw: torch.Size([512, 128])\n",
      "cw_index: 263, cw: torch.Size([512])\n",
      "cw_index: 264, cw: torch.Size([512])\n",
      "cw_index: 265, cw: torch.Size([512])\n",
      "cw_index: 266, cw: torch.Size([512])\n",
      "cw_index: 267, cw: torch.Size([512])\n",
      "cw_index: 268, cw: torch.Size([9521, 512])\n",
      "p_index: 0, name: encoder.src_word_emb.weight, param size: torch.Size([9521, 512]), collected weight size: torch.Size([9521, 512])\n",
      "p_index: 1, name: encoder.position_enc.pos_table, param size: torch.Size([1, 200, 512]), collected weight size: torch.Size([1, 200, 512])\n",
      "p_index: 2, name: encoder.layer_stack.0.slf_attn.w_qs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 3, name: encoder.layer_stack.0.slf_attn.w_ks.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 4, name: encoder.layer_stack.0.slf_attn.w_vs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 5, name: encoder.layer_stack.0.slf_attn.fc.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 6, name: encoder.layer_stack.0.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 7, name: encoder.layer_stack.0.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 8, name: encoder.layer_stack.0.pos_ffn.w_1.weight, param size: torch.Size([2048, 512]), collected weight size: torch.Size([2048, 512])\n",
      "p_index: 9, name: encoder.layer_stack.0.pos_ffn.w_1.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 10, name: encoder.layer_stack.0.pos_ffn.w_2.weight, param size: torch.Size([512, 2048]), collected weight size: torch.Size([512, 2048])\n",
      "p_index: 11, name: encoder.layer_stack.0.pos_ffn.w_2.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 12, name: encoder.layer_stack.0.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 13, name: encoder.layer_stack.0.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 14, name: encoder.layer_stack.1.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 15, name: encoder.layer_stack.1.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 16, name: encoder.layer_stack.1.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 17, name: encoder.layer_stack.1.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 18, name: encoder.layer_stack.1.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 19, name: encoder.layer_stack.1.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 20, name: encoder.layer_stack.1.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 21, name: encoder.layer_stack.1.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 22, name: encoder.layer_stack.1.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 23, name: encoder.layer_stack.1.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 24, name: encoder.layer_stack.1.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 25, name: encoder.layer_stack.1.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 26, name: encoder.layer_stack.1.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 27, name: encoder.layer_stack.1.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 28, name: encoder.layer_stack.1.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 29, name: encoder.layer_stack.1.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 30, name: encoder.layer_stack.1.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 31, name: encoder.layer_stack.1.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 32, name: encoder.layer_stack.2.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 33, name: encoder.layer_stack.2.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 34, name: encoder.layer_stack.2.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 35, name: encoder.layer_stack.2.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 36, name: encoder.layer_stack.2.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 37, name: encoder.layer_stack.2.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 38, name: encoder.layer_stack.2.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 39, name: encoder.layer_stack.2.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 40, name: encoder.layer_stack.2.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 41, name: encoder.layer_stack.2.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 42, name: encoder.layer_stack.2.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 43, name: encoder.layer_stack.2.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 44, name: encoder.layer_stack.2.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 45, name: encoder.layer_stack.2.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 46, name: encoder.layer_stack.2.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 47, name: encoder.layer_stack.2.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 48, name: encoder.layer_stack.2.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 49, name: encoder.layer_stack.2.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 50, name: encoder.layer_stack.3.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 51, name: encoder.layer_stack.3.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 52, name: encoder.layer_stack.3.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 53, name: encoder.layer_stack.3.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 54, name: encoder.layer_stack.3.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 55, name: encoder.layer_stack.3.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 56, name: encoder.layer_stack.3.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 57, name: encoder.layer_stack.3.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 58, name: encoder.layer_stack.3.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 59, name: encoder.layer_stack.3.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 60, name: encoder.layer_stack.3.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 61, name: encoder.layer_stack.3.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 62, name: encoder.layer_stack.3.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 63, name: encoder.layer_stack.3.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 64, name: encoder.layer_stack.3.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 65, name: encoder.layer_stack.3.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 66, name: encoder.layer_stack.3.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 67, name: encoder.layer_stack.3.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 68, name: encoder.layer_stack.4.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 69, name: encoder.layer_stack.4.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 70, name: encoder.layer_stack.4.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 71, name: encoder.layer_stack.4.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 72, name: encoder.layer_stack.4.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 73, name: encoder.layer_stack.4.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 74, name: encoder.layer_stack.4.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 75, name: encoder.layer_stack.4.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 76, name: encoder.layer_stack.4.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 77, name: encoder.layer_stack.4.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 78, name: encoder.layer_stack.4.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 79, name: encoder.layer_stack.4.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 80, name: encoder.layer_stack.4.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 81, name: encoder.layer_stack.4.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 82, name: encoder.layer_stack.4.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 83, name: encoder.layer_stack.4.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 84, name: encoder.layer_stack.4.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 85, name: encoder.layer_stack.4.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 86, name: encoder.layer_stack.5.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 87, name: encoder.layer_stack.5.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 88, name: encoder.layer_stack.5.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 89, name: encoder.layer_stack.5.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 90, name: encoder.layer_stack.5.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 91, name: encoder.layer_stack.5.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 92, name: encoder.layer_stack.5.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 93, name: encoder.layer_stack.5.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 94, name: encoder.layer_stack.5.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 95, name: encoder.layer_stack.5.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 96, name: encoder.layer_stack.5.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 97, name: encoder.layer_stack.5.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 98, name: encoder.layer_stack.5.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 99, name: encoder.layer_stack.5.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 100, name: encoder.layer_stack.5.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 101, name: encoder.layer_stack.5.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 102, name: encoder.layer_stack.5.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 103, name: encoder.layer_stack.5.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 104, name: encoder.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 105, name: encoder.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 106, name: decoder.trg_word_emb.weight, param size: torch.Size([9521, 512]), collected weight size: torch.Size([9521, 512])\n",
      "p_index: 107, name: decoder.position_enc.pos_table, param size: torch.Size([1, 200, 512]), collected weight size: torch.Size([1, 200, 512])\n",
      "p_index: 108, name: decoder.layer_stack.0.slf_attn.w_qs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 109, name: decoder.layer_stack.0.slf_attn.w_ks.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 110, name: decoder.layer_stack.0.slf_attn.w_vs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 111, name: decoder.layer_stack.0.slf_attn.fc.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 112, name: decoder.layer_stack.0.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 113, name: decoder.layer_stack.0.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 114, name: decoder.layer_stack.0.enc_attn.w_qs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 115, name: decoder.layer_stack.0.enc_attn.w_ks.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 116, name: decoder.layer_stack.0.enc_attn.w_vs.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 117, name: decoder.layer_stack.0.enc_attn.fc.weight, param size: torch.Size([512, 512]), collected weight size: torch.Size([512, 512])\n",
      "p_index: 118, name: decoder.layer_stack.0.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 119, name: decoder.layer_stack.0.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 120, name: decoder.layer_stack.0.pos_ffn.w_1.weight, param size: torch.Size([2048, 512]), collected weight size: torch.Size([2048, 512])\n",
      "p_index: 121, name: decoder.layer_stack.0.pos_ffn.w_1.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 122, name: decoder.layer_stack.0.pos_ffn.w_2.weight, param size: torch.Size([512, 2048]), collected weight size: torch.Size([512, 2048])\n",
      "p_index: 123, name: decoder.layer_stack.0.pos_ffn.w_2.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 124, name: decoder.layer_stack.0.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 125, name: decoder.layer_stack.0.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 126, name: decoder.layer_stack.1.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 127, name: decoder.layer_stack.1.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 128, name: decoder.layer_stack.1.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 129, name: decoder.layer_stack.1.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 130, name: decoder.layer_stack.1.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 131, name: decoder.layer_stack.1.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 132, name: decoder.layer_stack.1.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 133, name: decoder.layer_stack.1.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 134, name: decoder.layer_stack.1.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 135, name: decoder.layer_stack.1.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 136, name: decoder.layer_stack.1.enc_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 137, name: decoder.layer_stack.1.enc_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 138, name: decoder.layer_stack.1.enc_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 139, name: decoder.layer_stack.1.enc_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 140, name: decoder.layer_stack.1.enc_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 141, name: decoder.layer_stack.1.enc_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 142, name: decoder.layer_stack.1.enc_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 143, name: decoder.layer_stack.1.enc_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 144, name: decoder.layer_stack.1.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 145, name: decoder.layer_stack.1.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 146, name: decoder.layer_stack.1.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 147, name: decoder.layer_stack.1.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 148, name: decoder.layer_stack.1.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 149, name: decoder.layer_stack.1.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 150, name: decoder.layer_stack.1.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 151, name: decoder.layer_stack.1.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 152, name: decoder.layer_stack.1.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 153, name: decoder.layer_stack.1.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 154, name: decoder.layer_stack.2.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 155, name: decoder.layer_stack.2.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 156, name: decoder.layer_stack.2.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 157, name: decoder.layer_stack.2.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 158, name: decoder.layer_stack.2.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 159, name: decoder.layer_stack.2.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 160, name: decoder.layer_stack.2.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 161, name: decoder.layer_stack.2.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 162, name: decoder.layer_stack.2.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 163, name: decoder.layer_stack.2.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 164, name: decoder.layer_stack.2.enc_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 165, name: decoder.layer_stack.2.enc_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 166, name: decoder.layer_stack.2.enc_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 167, name: decoder.layer_stack.2.enc_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 168, name: decoder.layer_stack.2.enc_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 169, name: decoder.layer_stack.2.enc_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 170, name: decoder.layer_stack.2.enc_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 171, name: decoder.layer_stack.2.enc_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 172, name: decoder.layer_stack.2.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 173, name: decoder.layer_stack.2.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 174, name: decoder.layer_stack.2.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 175, name: decoder.layer_stack.2.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 176, name: decoder.layer_stack.2.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 177, name: decoder.layer_stack.2.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 178, name: decoder.layer_stack.2.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 179, name: decoder.layer_stack.2.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 180, name: decoder.layer_stack.2.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 181, name: decoder.layer_stack.2.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 182, name: decoder.layer_stack.3.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 183, name: decoder.layer_stack.3.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 184, name: decoder.layer_stack.3.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 185, name: decoder.layer_stack.3.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 186, name: decoder.layer_stack.3.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 187, name: decoder.layer_stack.3.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 188, name: decoder.layer_stack.3.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 189, name: decoder.layer_stack.3.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 190, name: decoder.layer_stack.3.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 191, name: decoder.layer_stack.3.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 192, name: decoder.layer_stack.3.enc_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 193, name: decoder.layer_stack.3.enc_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 194, name: decoder.layer_stack.3.enc_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 195, name: decoder.layer_stack.3.enc_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 196, name: decoder.layer_stack.3.enc_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 197, name: decoder.layer_stack.3.enc_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 198, name: decoder.layer_stack.3.enc_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 199, name: decoder.layer_stack.3.enc_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 200, name: decoder.layer_stack.3.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 201, name: decoder.layer_stack.3.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 202, name: decoder.layer_stack.3.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 203, name: decoder.layer_stack.3.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 204, name: decoder.layer_stack.3.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 205, name: decoder.layer_stack.3.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 206, name: decoder.layer_stack.3.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 207, name: decoder.layer_stack.3.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 208, name: decoder.layer_stack.3.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 209, name: decoder.layer_stack.3.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 210, name: decoder.layer_stack.4.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 211, name: decoder.layer_stack.4.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 212, name: decoder.layer_stack.4.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 213, name: decoder.layer_stack.4.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 214, name: decoder.layer_stack.4.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 215, name: decoder.layer_stack.4.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 216, name: decoder.layer_stack.4.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 217, name: decoder.layer_stack.4.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 218, name: decoder.layer_stack.4.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 219, name: decoder.layer_stack.4.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 220, name: decoder.layer_stack.4.enc_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 221, name: decoder.layer_stack.4.enc_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 222, name: decoder.layer_stack.4.enc_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 223, name: decoder.layer_stack.4.enc_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 224, name: decoder.layer_stack.4.enc_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 225, name: decoder.layer_stack.4.enc_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 226, name: decoder.layer_stack.4.enc_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 227, name: decoder.layer_stack.4.enc_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 228, name: decoder.layer_stack.4.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 229, name: decoder.layer_stack.4.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 230, name: decoder.layer_stack.4.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 231, name: decoder.layer_stack.4.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 232, name: decoder.layer_stack.4.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 233, name: decoder.layer_stack.4.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 234, name: decoder.layer_stack.4.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 235, name: decoder.layer_stack.4.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 236, name: decoder.layer_stack.4.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 237, name: decoder.layer_stack.4.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 238, name: decoder.layer_stack.5.slf_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 239, name: decoder.layer_stack.5.slf_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 240, name: decoder.layer_stack.5.slf_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 241, name: decoder.layer_stack.5.slf_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 242, name: decoder.layer_stack.5.slf_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 243, name: decoder.layer_stack.5.slf_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 244, name: decoder.layer_stack.5.slf_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 245, name: decoder.layer_stack.5.slf_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 246, name: decoder.layer_stack.5.slf_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 247, name: decoder.layer_stack.5.slf_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 248, name: decoder.layer_stack.5.enc_attn.w_qs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 249, name: decoder.layer_stack.5.enc_attn.w_qs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 250, name: decoder.layer_stack.5.enc_attn.w_ks_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 251, name: decoder.layer_stack.5.enc_attn.w_ks_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 252, name: decoder.layer_stack.5.enc_attn.w_vs_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 253, name: decoder.layer_stack.5.enc_attn.w_vs_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 254, name: decoder.layer_stack.5.enc_attn.fc_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 255, name: decoder.layer_stack.5.enc_attn.fc_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 256, name: decoder.layer_stack.5.enc_attn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 257, name: decoder.layer_stack.5.enc_attn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 258, name: decoder.layer_stack.5.pos_ffn.w_1_u.weight, param size: torch.Size([128, 512]), collected weight size: torch.Size([128, 512])\n",
      "p_index: 259, name: decoder.layer_stack.5.pos_ffn.w_1_v.weight, param size: torch.Size([2048, 128]), collected weight size: torch.Size([2048, 128])\n",
      "p_index: 260, name: decoder.layer_stack.5.pos_ffn.w_1_v.bias, param size: torch.Size([2048]), collected weight size: torch.Size([2048])\n",
      "p_index: 261, name: decoder.layer_stack.5.pos_ffn.w_2_u.weight, param size: torch.Size([128, 2048]), collected weight size: torch.Size([128, 2048])\n",
      "p_index: 262, name: decoder.layer_stack.5.pos_ffn.w_2_v.weight, param size: torch.Size([512, 128]), collected weight size: torch.Size([512, 128])\n",
      "p_index: 263, name: decoder.layer_stack.5.pos_ffn.w_2_v.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 264, name: decoder.layer_stack.5.pos_ffn.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 265, name: decoder.layer_stack.5.pos_ffn.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 266, name: decoder.layer_norm.weight, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 267, name: decoder.layer_norm.bias, param size: torch.Size([512]), collected weight size: torch.Size([512])\n",
      "p_index: 268, name: trg_word_prj.weight, param size: torch.Size([9521, 512]), collected weight size: torch.Size([9521, 512])\n"
     ]
    }
   ],
   "source": [
    "loaded_lr_model = decompose_vanilla_model(vanilla_model=transformer, low_rank_model=lr_transformer, rank_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
