{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm part\n",
    "#from word_language_model.model import RNNModel, LowRankRNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongyiwang/anaconda3/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py:114: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_resnet50_2_model = models.wide_resnet50_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 11.44 GMac, params: 68.88 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(wide_resnet50_2_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_wide_resnet50_2_model = models.hybrid_wide_resnet50_2(rank_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 9.99 GMac, params: 40.05 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(hybrid_wide_resnet50_2_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 4.12 GMac, params: 25.56 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(resnet50_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_resnet50_model = models.hybrid_resnet50(rank_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 3.6 GMac, params: 15.2 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(hybrid_resnet50_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_cifar10 import *\n",
    "from lowrank_vgg import LowRankVGG, FullRankVGG, FullRankVGG19, LowRankVGG19, LowRankVGG19NonSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_cifar10 import LowrankResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model = LowrankResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 3, 3])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.1.conv1_u.weight torch.Size([16, 64, 3, 3])\n",
      "layer1.1.conv1_v.weight torch.Size([64, 16, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2_u.weight torch.Size([16, 64, 3, 3])\n",
      "layer1.1.conv2_v.weight torch.Size([64, 16, 1, 1])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer2.0.conv1_u.weight torch.Size([32, 64, 3, 3])\n",
      "layer2.0.conv1_v.weight torch.Size([128, 32, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2_u.weight torch.Size([32, 128, 3, 3])\n",
      "layer2.0.conv2_v.weight torch.Size([128, 32, 1, 1])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])\n",
      "layer2.0.shortcut.1.weight torch.Size([128])\n",
      "layer2.0.shortcut.1.bias torch.Size([128])\n",
      "layer2.1.conv1_u.weight torch.Size([32, 128, 3, 3])\n",
      "layer2.1.conv1_v.weight torch.Size([128, 32, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2_u.weight torch.Size([32, 128, 3, 3])\n",
      "layer2.1.conv2_v.weight torch.Size([128, 32, 1, 1])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer3.0.conv1_u.weight torch.Size([64, 128, 3, 3])\n",
      "layer3.0.conv1_v.weight torch.Size([256, 64, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2_u.weight torch.Size([64, 256, 3, 3])\n",
      "layer3.0.conv2_v.weight torch.Size([256, 64, 1, 1])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])\n",
      "layer3.0.shortcut.1.weight torch.Size([256])\n",
      "layer3.0.shortcut.1.bias torch.Size([256])\n",
      "layer3.1.conv1_u.weight torch.Size([64, 256, 3, 3])\n",
      "layer3.1.conv1_v.weight torch.Size([256, 64, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2_u.weight torch.Size([64, 256, 3, 3])\n",
      "layer3.1.conv2_v.weight torch.Size([256, 64, 1, 1])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer4.0.conv1_u.weight torch.Size([128, 256, 3, 3])\n",
      "layer4.0.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "layer4.0.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.shortcut.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer4.0.shortcut.1.weight torch.Size([512])\n",
      "layer4.0.shortcut.1.bias torch.Size([512])\n",
      "layer4.1.conv1_u.weight torch.Size([128, 512, 3, 3])\n",
      "layer4.1.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "layer4.1.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "linear.weight torch.Size([10, 512])\n",
      "linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet18_model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6535626\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for item_index, param in enumerate(resnet18_model.parameters()):\n",
    "    num_params += param.nelement()\n",
    "    #print(item_index, param.size())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 0.28 GMac, params: 6.54 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(resnet18_model, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_resnet50 = models.hybrid_resnet50(rank_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 3.6 GMac, params: 15.2 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(hybrid_resnet50, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowrank_resnet18_model = LowrankResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lowrank_resnet18_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336138\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for item_index, param in enumerate(lowrank_resnet18_model.parameters()):\n",
    "    num_params += param.nelement()\n",
    "    #print(item_index, param.size())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 0.22 GMac, params: 3.34 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(lowrank_resnet18_model, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count MACs of LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank_model = models.__dict__[\"hybrid_resnet50\"]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model = models.__dict__[\"resnet50\"]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 4.12 GMac, params: 25.56 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(vanilla_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 3.6 GMac, params: 15.2 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(low_rank_model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_weights(model, low_rank_model, rank_factor):\n",
    "    # SVD version\n",
    "    reconstructed_aggregator = []\n",
    "\n",
    "    for item_index, (param_name, param) in enumerate(model.state_dict().items()):\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 258) and \"downsample\" not in param_name and \"conv3\" not in param_name:\n",
    "        if len(param.size()) == 4 and item_index not in range(0, 258):\n",
    "            # resize --> svd --> two layer\n",
    "            param_reshaped = param.view(param.size()[0], -1)\n",
    "            rank = min(param_reshaped.size()[0], param_reshaped.size()[1])\n",
    "            u, s, v = torch.svd(param_reshaped)\n",
    "\n",
    "            sliced_rank = int(rank/rank_factor)\n",
    "            u_weight = u * torch.sqrt(s)\n",
    "            v_weight = torch.sqrt(s) * v\n",
    "            u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "\n",
    "            u_weight_sliced_shape, v_weight_sliced_shape = u_weight_sliced.size(), v_weight_sliced.size()\n",
    "\n",
    "            #model_weight_v = u_weight.view(u_weight_sliced_shape[0],\n",
    "            model_weight_v = u_weight_sliced.view(u_weight_sliced_shape[0],\n",
    "                                                  u_weight_sliced_shape[1], 1, 1)\n",
    "            \n",
    "            #model_weight_u = v_weight.t().view(v_weight_sliced_shape[1], \n",
    "            model_weight_u = v_weight_sliced.t().view(v_weight_sliced_shape[1], \n",
    "                                                      param.size()[1], \n",
    "                                                      param.size()[2], \n",
    "                                                      param.size()[3])\n",
    "\n",
    "            #if \"downsample\" in param_name:\n",
    "            #    print(\"@@@@ U size: {}, V size: {}\".format(model_weight_u.size(), model_weight_v.size()))\n",
    "            reconstructed_aggregator.append(model_weight_u)\n",
    "            reconstructed_aggregator.append(model_weight_v)\n",
    "        else:\n",
    "            reconstructed_aggregator.append(param)\n",
    "            \n",
    "    \n",
    "    #for ra_index, ra in enumerate(reconstructed_aggregator):\n",
    "    #    print(\"ra index: {}, ra size: {}\".format(ra_index, ra.size()))\n",
    "            \n",
    "    model_counter = 0\n",
    "    reload_state_dict = {}\n",
    "    for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "        print(\"#### {}, {}, recons agg: {}， param: {}\".format(item_index, param_name, \n",
    "                                                                                reconstructed_aggregator[model_counter].size(),\n",
    "                                                                               param.size()))\n",
    "        assert (reconstructed_aggregator[model_counter].size() == param.size())\n",
    "        reload_state_dict[param_name] = reconstructed_aggregator[model_counter]\n",
    "        model_counter += 1\n",
    "    low_rank_model.load_state_dict(reload_state_dict)\n",
    "    return low_rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 0, conv1.weight, recons agg: torch.Size([64, 3, 7, 7])， param: torch.Size([64, 3, 7, 7])\n",
      "#### 1, bn1.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 2, bn1.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 3, bn1.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 4, bn1.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 5, bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 6, layer1.0.conv1.weight, recons agg: torch.Size([128, 64, 1, 1])， param: torch.Size([128, 64, 1, 1])\n",
      "#### 7, layer1.0.bn1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 8, layer1.0.bn1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 9, layer1.0.bn1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 10, layer1.0.bn1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 11, layer1.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 12, layer1.0.conv2.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 13, layer1.0.bn2.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 14, layer1.0.bn2.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 15, layer1.0.bn2.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 16, layer1.0.bn2.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 17, layer1.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 18, layer1.0.conv3.weight, recons agg: torch.Size([256, 128, 1, 1])， param: torch.Size([256, 128, 1, 1])\n",
      "#### 19, layer1.0.bn3.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 20, layer1.0.bn3.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 21, layer1.0.bn3.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 22, layer1.0.bn3.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 23, layer1.0.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 24, layer1.0.downsample.0.weight, recons agg: torch.Size([256, 64, 1, 1])， param: torch.Size([256, 64, 1, 1])\n",
      "#### 25, layer1.0.downsample.1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 26, layer1.0.downsample.1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 27, layer1.0.downsample.1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 28, layer1.0.downsample.1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 29, layer1.0.downsample.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 30, layer1.1.conv1.weight, recons agg: torch.Size([128, 256, 1, 1])， param: torch.Size([128, 256, 1, 1])\n",
      "#### 31, layer1.1.bn1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 32, layer1.1.bn1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 33, layer1.1.bn1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 34, layer1.1.bn1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 35, layer1.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 36, layer1.1.conv2.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 37, layer1.1.bn2.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 38, layer1.1.bn2.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 39, layer1.1.bn2.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 40, layer1.1.bn2.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 41, layer1.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 42, layer1.1.conv3.weight, recons agg: torch.Size([256, 128, 1, 1])， param: torch.Size([256, 128, 1, 1])\n",
      "#### 43, layer1.1.bn3.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 44, layer1.1.bn3.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 45, layer1.1.bn3.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 46, layer1.1.bn3.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 47, layer1.1.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 48, layer1.2.conv1.weight, recons agg: torch.Size([128, 256, 1, 1])， param: torch.Size([128, 256, 1, 1])\n",
      "#### 49, layer1.2.bn1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 50, layer1.2.bn1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 51, layer1.2.bn1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 52, layer1.2.bn1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 53, layer1.2.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 54, layer1.2.conv2.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 55, layer1.2.bn2.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 56, layer1.2.bn2.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 57, layer1.2.bn2.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 58, layer1.2.bn2.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 59, layer1.2.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 60, layer1.2.conv3.weight, recons agg: torch.Size([256, 128, 1, 1])， param: torch.Size([256, 128, 1, 1])\n",
      "#### 61, layer1.2.bn3.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 62, layer1.2.bn3.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 63, layer1.2.bn3.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 64, layer1.2.bn3.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 65, layer1.2.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 66, layer2.0.conv1.weight, recons agg: torch.Size([256, 256, 1, 1])， param: torch.Size([256, 256, 1, 1])\n",
      "#### 67, layer2.0.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 68, layer2.0.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 69, layer2.0.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 70, layer2.0.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 71, layer2.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 72, layer2.0.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 73, layer2.0.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 74, layer2.0.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 75, layer2.0.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 76, layer2.0.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 77, layer2.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 78, layer2.0.conv3.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 79, layer2.0.bn3.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 80, layer2.0.bn3.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 81, layer2.0.bn3.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 82, layer2.0.bn3.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 83, layer2.0.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 84, layer2.0.downsample.0.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 85, layer2.0.downsample.1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 86, layer2.0.downsample.1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 87, layer2.0.downsample.1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 88, layer2.0.downsample.1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 89, layer2.0.downsample.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 90, layer2.1.conv1.weight, recons agg: torch.Size([256, 512, 1, 1])， param: torch.Size([256, 512, 1, 1])\n",
      "#### 91, layer2.1.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 92, layer2.1.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 93, layer2.1.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 94, layer2.1.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 95, layer2.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 96, layer2.1.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 97, layer2.1.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 98, layer2.1.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 99, layer2.1.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 100, layer2.1.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 101, layer2.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 102, layer2.1.conv3.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 103, layer2.1.bn3.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 104, layer2.1.bn3.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 105, layer2.1.bn3.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 106, layer2.1.bn3.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 107, layer2.1.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 108, layer2.2.conv1.weight, recons agg: torch.Size([256, 512, 1, 1])， param: torch.Size([256, 512, 1, 1])\n",
      "#### 109, layer2.2.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 110, layer2.2.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 111, layer2.2.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 112, layer2.2.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 113, layer2.2.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 114, layer2.2.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 115, layer2.2.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 116, layer2.2.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 117, layer2.2.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 118, layer2.2.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 119, layer2.2.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 120, layer2.2.conv3.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 121, layer2.2.bn3.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 122, layer2.2.bn3.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 123, layer2.2.bn3.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 124, layer2.2.bn3.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 125, layer2.2.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 126, layer2.3.conv1.weight, recons agg: torch.Size([256, 512, 1, 1])， param: torch.Size([256, 512, 1, 1])\n",
      "#### 127, layer2.3.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 128, layer2.3.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 129, layer2.3.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 130, layer2.3.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 131, layer2.3.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 132, layer2.3.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 133, layer2.3.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 134, layer2.3.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 135, layer2.3.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 136, layer2.3.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 137, layer2.3.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 138, layer2.3.conv3.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 139, layer2.3.bn3.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 140, layer2.3.bn3.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 141, layer2.3.bn3.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 142, layer2.3.bn3.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 143, layer2.3.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 144, layer3.0.conv1.weight, recons agg: torch.Size([512, 512, 1, 1])， param: torch.Size([512, 512, 1, 1])\n",
      "#### 145, layer3.0.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 146, layer3.0.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 147, layer3.0.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 148, layer3.0.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 149, layer3.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 150, layer3.0.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 151, layer3.0.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 152, layer3.0.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 153, layer3.0.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 154, layer3.0.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 155, layer3.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 156, layer3.0.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 157, layer3.0.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 158, layer3.0.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 159, layer3.0.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 160, layer3.0.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 161, layer3.0.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 162, layer3.0.downsample.0.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 163, layer3.0.downsample.1.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 164, layer3.0.downsample.1.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 165, layer3.0.downsample.1.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 166, layer3.0.downsample.1.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 167, layer3.0.downsample.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 168, layer3.1.conv1.weight, recons agg: torch.Size([512, 1024, 1, 1])， param: torch.Size([512, 1024, 1, 1])\n",
      "#### 169, layer3.1.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 170, layer3.1.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 171, layer3.1.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 172, layer3.1.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 173, layer3.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 174, layer3.1.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 175, layer3.1.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 176, layer3.1.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 177, layer3.1.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 178, layer3.1.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 179, layer3.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 180, layer3.1.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 181, layer3.1.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 182, layer3.1.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 183, layer3.1.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 184, layer3.1.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 185, layer3.1.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 186, layer3.2.conv1.weight, recons agg: torch.Size([512, 1024, 1, 1])， param: torch.Size([512, 1024, 1, 1])\n",
      "#### 187, layer3.2.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 188, layer3.2.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 189, layer3.2.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 190, layer3.2.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 191, layer3.2.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 192, layer3.2.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 193, layer3.2.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 194, layer3.2.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 195, layer3.2.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 196, layer3.2.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 197, layer3.2.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 198, layer3.2.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 199, layer3.2.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 200, layer3.2.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 201, layer3.2.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 202, layer3.2.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 203, layer3.2.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 204, layer3.3.conv1.weight, recons agg: torch.Size([512, 1024, 1, 1])， param: torch.Size([512, 1024, 1, 1])\n",
      "#### 205, layer3.3.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 206, layer3.3.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 207, layer3.3.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 208, layer3.3.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 209, layer3.3.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 210, layer3.3.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 211, layer3.3.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 212, layer3.3.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 213, layer3.3.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 214, layer3.3.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 215, layer3.3.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 216, layer3.3.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 217, layer3.3.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 218, layer3.3.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 219, layer3.3.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 220, layer3.3.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 221, layer3.3.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 222, layer3.4.conv1.weight, recons agg: torch.Size([512, 1024, 1, 1])， param: torch.Size([512, 1024, 1, 1])\n",
      "#### 223, layer3.4.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 224, layer3.4.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 225, layer3.4.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 226, layer3.4.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 227, layer3.4.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 228, layer3.4.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 229, layer3.4.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 230, layer3.4.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 231, layer3.4.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 232, layer3.4.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 233, layer3.4.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 234, layer3.4.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 235, layer3.4.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 236, layer3.4.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 237, layer3.4.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 238, layer3.4.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 239, layer3.4.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 240, layer3.5.conv1.weight, recons agg: torch.Size([512, 1024, 1, 1])， param: torch.Size([512, 1024, 1, 1])\n",
      "#### 241, layer3.5.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 242, layer3.5.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 243, layer3.5.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 244, layer3.5.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 245, layer3.5.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 246, layer3.5.conv2.weight, recons agg: torch.Size([512, 512, 3, 3])， param: torch.Size([512, 512, 3, 3])\n",
      "#### 247, layer3.5.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 248, layer3.5.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 249, layer3.5.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 250, layer3.5.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 251, layer3.5.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 252, layer3.5.conv3.weight, recons agg: torch.Size([1024, 512, 1, 1])， param: torch.Size([1024, 512, 1, 1])\n",
      "#### 253, layer3.5.bn3.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 254, layer3.5.bn3.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 255, layer3.5.bn3.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 256, layer3.5.bn3.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 257, layer3.5.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 258, layer4.0.conv1_u.weight, recons agg: torch.Size([256, 1024, 1, 1])， param: torch.Size([256, 1024, 1, 1])\n",
      "#### 259, layer4.0.conv1_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 260, layer4.0.bn1.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 261, layer4.0.bn1.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 262, layer4.0.bn1.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 263, layer4.0.bn1.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 264, layer4.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 265, layer4.0.conv2_u.weight, recons agg: torch.Size([256, 1024, 3, 3])， param: torch.Size([256, 1024, 3, 3])\n",
      "#### 266, layer4.0.conv2_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 267, layer4.0.bn2.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 268, layer4.0.bn2.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 269, layer4.0.bn2.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 270, layer4.0.bn2.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 271, layer4.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 272, layer4.0.conv3_u.weight, recons agg: torch.Size([256, 1024, 1, 1])， param: torch.Size([256, 1024, 1, 1])\n",
      "#### 273, layer4.0.conv3_v.weight, recons agg: torch.Size([2048, 256, 1, 1])， param: torch.Size([2048, 256, 1, 1])\n",
      "#### 274, layer4.0.bn3.weight, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 275, layer4.0.bn3.bias, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 276, layer4.0.bn3.running_mean, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 277, layer4.0.bn3.running_var, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 278, layer4.0.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 279, layer4.0.downsample.0.weight, recons agg: torch.Size([256, 1024, 1, 1])， param: torch.Size([256, 1024, 1, 1])\n",
      "#### 280, layer4.0.downsample.1.weight, recons agg: torch.Size([2048, 256, 1, 1])， param: torch.Size([2048, 256, 1, 1])\n",
      "#### 281, layer4.0.downsample.2.weight, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 282, layer4.0.downsample.2.bias, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 283, layer4.0.downsample.2.running_mean, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 284, layer4.0.downsample.2.running_var, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 285, layer4.0.downsample.2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 286, layer4.1.conv1_u.weight, recons agg: torch.Size([256, 2048, 1, 1])， param: torch.Size([256, 2048, 1, 1])\n",
      "#### 287, layer4.1.conv1_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 288, layer4.1.bn1.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 289, layer4.1.bn1.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 290, layer4.1.bn1.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 291, layer4.1.bn1.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 292, layer4.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 293, layer4.1.conv2_u.weight, recons agg: torch.Size([256, 1024, 3, 3])， param: torch.Size([256, 1024, 3, 3])\n",
      "#### 294, layer4.1.conv2_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 295, layer4.1.bn2.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 296, layer4.1.bn2.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 297, layer4.1.bn2.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 298, layer4.1.bn2.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 299, layer4.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 300, layer4.1.conv3_u.weight, recons agg: torch.Size([256, 1024, 1, 1])， param: torch.Size([256, 1024, 1, 1])\n",
      "#### 301, layer4.1.conv3_v.weight, recons agg: torch.Size([2048, 256, 1, 1])， param: torch.Size([2048, 256, 1, 1])\n",
      "#### 302, layer4.1.bn3.weight, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 303, layer4.1.bn3.bias, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 304, layer4.1.bn3.running_mean, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 305, layer4.1.bn3.running_var, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 306, layer4.1.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 307, layer4.2.conv1_u.weight, recons agg: torch.Size([256, 2048, 1, 1])， param: torch.Size([256, 2048, 1, 1])\n",
      "#### 308, layer4.2.conv1_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 309, layer4.2.bn1.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 310, layer4.2.bn1.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 311, layer4.2.bn1.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 312, layer4.2.bn1.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 313, layer4.2.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 314, layer4.2.conv2_u.weight, recons agg: torch.Size([256, 1024, 3, 3])， param: torch.Size([256, 1024, 3, 3])\n",
      "#### 315, layer4.2.conv2_v.weight, recons agg: torch.Size([1024, 256, 1, 1])， param: torch.Size([1024, 256, 1, 1])\n",
      "#### 316, layer4.2.bn2.weight, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 317, layer4.2.bn2.bias, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 318, layer4.2.bn2.running_mean, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 319, layer4.2.bn2.running_var, recons agg: torch.Size([1024])， param: torch.Size([1024])\n",
      "#### 320, layer4.2.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 321, layer4.2.conv3_u.weight, recons agg: torch.Size([256, 1024, 1, 1])， param: torch.Size([256, 1024, 1, 1])\n",
      "#### 322, layer4.2.conv3_v.weight, recons agg: torch.Size([2048, 256, 1, 1])， param: torch.Size([2048, 256, 1, 1])\n",
      "#### 323, layer4.2.bn3.weight, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 324, layer4.2.bn3.bias, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 325, layer4.2.bn3.running_mean, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 326, layer4.2.bn3.running_var, recons agg: torch.Size([2048])， param: torch.Size([2048])\n",
      "#### 327, layer4.2.bn3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 328, fc.weight, recons agg: torch.Size([1000, 2048])， param: torch.Size([1000, 2048])\n",
      "#### 329, fc.bias, recons agg: torch.Size([1000])， param: torch.Size([1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HybridResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): LowRankBottleneckConv1x1(\n",
       "      (conv1_u): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_u): Conv2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3_u): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv3_v): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): LowRankBottleneckConv1x1(\n",
       "      (conv1_u): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_u): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3_u): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv3_v): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): LowRankBottleneckConv1x1(\n",
       "      (conv1_u): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_u): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2_v): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3_u): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv3_v): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose_weights(model=vanilla_model, low_rank_model=low_rank_model, rank_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15202344\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for item_index, param in enumerate(low_rank_model.parameters()):\n",
    "    num_params += param.nelement()\n",
    "    #print(item_index, param.size())\n",
    "    \n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 7, 7])\n",
      "1 bn1.weight torch.Size([64])\n",
      "2 bn1.bias torch.Size([64])\n",
      "3 bn1.running_mean torch.Size([64])\n",
      "4 bn1.running_var torch.Size([64])\n",
      "5 bn1.num_batches_tracked torch.Size([])\n",
      "6 layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "7 layer1.0.bn1.weight torch.Size([64])\n",
      "8 layer1.0.bn1.bias torch.Size([64])\n",
      "9 layer1.0.bn1.running_mean torch.Size([64])\n",
      "10 layer1.0.bn1.running_var torch.Size([64])\n",
      "11 layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "12 layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "13 layer1.0.bn2.weight torch.Size([64])\n",
      "14 layer1.0.bn2.bias torch.Size([64])\n",
      "15 layer1.0.bn2.running_mean torch.Size([64])\n",
      "16 layer1.0.bn2.running_var torch.Size([64])\n",
      "17 layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "18 layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "19 layer1.0.bn3.weight torch.Size([256])\n",
      "20 layer1.0.bn3.bias torch.Size([256])\n",
      "21 layer1.0.bn3.running_mean torch.Size([256])\n",
      "22 layer1.0.bn3.running_var torch.Size([256])\n",
      "23 layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "24 layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "25 layer1.0.downsample.1.weight torch.Size([256])\n",
      "26 layer1.0.downsample.1.bias torch.Size([256])\n",
      "27 layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "28 layer1.0.downsample.1.running_var torch.Size([256])\n",
      "29 layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "30 layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "31 layer1.1.bn1.weight torch.Size([64])\n",
      "32 layer1.1.bn1.bias torch.Size([64])\n",
      "33 layer1.1.bn1.running_mean torch.Size([64])\n",
      "34 layer1.1.bn1.running_var torch.Size([64])\n",
      "35 layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "36 layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "37 layer1.1.bn2.weight torch.Size([64])\n",
      "38 layer1.1.bn2.bias torch.Size([64])\n",
      "39 layer1.1.bn2.running_mean torch.Size([64])\n",
      "40 layer1.1.bn2.running_var torch.Size([64])\n",
      "41 layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "42 layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "43 layer1.1.bn3.weight torch.Size([256])\n",
      "44 layer1.1.bn3.bias torch.Size([256])\n",
      "45 layer1.1.bn3.running_mean torch.Size([256])\n",
      "46 layer1.1.bn3.running_var torch.Size([256])\n",
      "47 layer1.1.bn3.num_batches_tracked torch.Size([])\n",
      "48 layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "49 layer1.2.bn1.weight torch.Size([64])\n",
      "50 layer1.2.bn1.bias torch.Size([64])\n",
      "51 layer1.2.bn1.running_mean torch.Size([64])\n",
      "52 layer1.2.bn1.running_var torch.Size([64])\n",
      "53 layer1.2.bn1.num_batches_tracked torch.Size([])\n",
      "54 layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "55 layer1.2.bn2.weight torch.Size([64])\n",
      "56 layer1.2.bn2.bias torch.Size([64])\n",
      "57 layer1.2.bn2.running_mean torch.Size([64])\n",
      "58 layer1.2.bn2.running_var torch.Size([64])\n",
      "59 layer1.2.bn2.num_batches_tracked torch.Size([])\n",
      "60 layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "61 layer1.2.bn3.weight torch.Size([256])\n",
      "62 layer1.2.bn3.bias torch.Size([256])\n",
      "63 layer1.2.bn3.running_mean torch.Size([256])\n",
      "64 layer1.2.bn3.running_var torch.Size([256])\n",
      "65 layer1.2.bn3.num_batches_tracked torch.Size([])\n",
      "66 layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "67 layer2.0.bn1.weight torch.Size([128])\n",
      "68 layer2.0.bn1.bias torch.Size([128])\n",
      "69 layer2.0.bn1.running_mean torch.Size([128])\n",
      "70 layer2.0.bn1.running_var torch.Size([128])\n",
      "71 layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "72 layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "73 layer2.0.bn2.weight torch.Size([128])\n",
      "74 layer2.0.bn2.bias torch.Size([128])\n",
      "75 layer2.0.bn2.running_mean torch.Size([128])\n",
      "76 layer2.0.bn2.running_var torch.Size([128])\n",
      "77 layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "78 layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "79 layer2.0.bn3.weight torch.Size([512])\n",
      "80 layer2.0.bn3.bias torch.Size([512])\n",
      "81 layer2.0.bn3.running_mean torch.Size([512])\n",
      "82 layer2.0.bn3.running_var torch.Size([512])\n",
      "83 layer2.0.bn3.num_batches_tracked torch.Size([])\n",
      "84 layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "85 layer2.0.downsample.1.weight torch.Size([512])\n",
      "86 layer2.0.downsample.1.bias torch.Size([512])\n",
      "87 layer2.0.downsample.1.running_mean torch.Size([512])\n",
      "88 layer2.0.downsample.1.running_var torch.Size([512])\n",
      "89 layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "90 layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "91 layer2.1.bn1.weight torch.Size([128])\n",
      "92 layer2.1.bn1.bias torch.Size([128])\n",
      "93 layer2.1.bn1.running_mean torch.Size([128])\n",
      "94 layer2.1.bn1.running_var torch.Size([128])\n",
      "95 layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "96 layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "97 layer2.1.bn2.weight torch.Size([128])\n",
      "98 layer2.1.bn2.bias torch.Size([128])\n",
      "99 layer2.1.bn2.running_mean torch.Size([128])\n",
      "100 layer2.1.bn2.running_var torch.Size([128])\n",
      "101 layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "102 layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "103 layer2.1.bn3.weight torch.Size([512])\n",
      "104 layer2.1.bn3.bias torch.Size([512])\n",
      "105 layer2.1.bn3.running_mean torch.Size([512])\n",
      "106 layer2.1.bn3.running_var torch.Size([512])\n",
      "107 layer2.1.bn3.num_batches_tracked torch.Size([])\n",
      "108 layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "109 layer2.2.bn1.weight torch.Size([128])\n",
      "110 layer2.2.bn1.bias torch.Size([128])\n",
      "111 layer2.2.bn1.running_mean torch.Size([128])\n",
      "112 layer2.2.bn1.running_var torch.Size([128])\n",
      "113 layer2.2.bn1.num_batches_tracked torch.Size([])\n",
      "114 layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "115 layer2.2.bn2.weight torch.Size([128])\n",
      "116 layer2.2.bn2.bias torch.Size([128])\n",
      "117 layer2.2.bn2.running_mean torch.Size([128])\n",
      "118 layer2.2.bn2.running_var torch.Size([128])\n",
      "119 layer2.2.bn2.num_batches_tracked torch.Size([])\n",
      "120 layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "121 layer2.2.bn3.weight torch.Size([512])\n",
      "122 layer2.2.bn3.bias torch.Size([512])\n",
      "123 layer2.2.bn3.running_mean torch.Size([512])\n",
      "124 layer2.2.bn3.running_var torch.Size([512])\n",
      "125 layer2.2.bn3.num_batches_tracked torch.Size([])\n",
      "126 layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "127 layer2.3.bn1.weight torch.Size([128])\n",
      "128 layer2.3.bn1.bias torch.Size([128])\n",
      "129 layer2.3.bn1.running_mean torch.Size([128])\n",
      "130 layer2.3.bn1.running_var torch.Size([128])\n",
      "131 layer2.3.bn1.num_batches_tracked torch.Size([])\n",
      "132 layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "133 layer2.3.bn2.weight torch.Size([128])\n",
      "134 layer2.3.bn2.bias torch.Size([128])\n",
      "135 layer2.3.bn2.running_mean torch.Size([128])\n",
      "136 layer2.3.bn2.running_var torch.Size([128])\n",
      "137 layer2.3.bn2.num_batches_tracked torch.Size([])\n",
      "138 layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "139 layer2.3.bn3.weight torch.Size([512])\n",
      "140 layer2.3.bn3.bias torch.Size([512])\n",
      "141 layer2.3.bn3.running_mean torch.Size([512])\n",
      "142 layer2.3.bn3.running_var torch.Size([512])\n",
      "143 layer2.3.bn3.num_batches_tracked torch.Size([])\n",
      "144 layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "145 layer3.0.bn1.weight torch.Size([256])\n",
      "146 layer3.0.bn1.bias torch.Size([256])\n",
      "147 layer3.0.bn1.running_mean torch.Size([256])\n",
      "148 layer3.0.bn1.running_var torch.Size([256])\n",
      "149 layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "150 layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "151 layer3.0.bn2.weight torch.Size([256])\n",
      "152 layer3.0.bn2.bias torch.Size([256])\n",
      "153 layer3.0.bn2.running_mean torch.Size([256])\n",
      "154 layer3.0.bn2.running_var torch.Size([256])\n",
      "155 layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "156 layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "157 layer3.0.bn3.weight torch.Size([1024])\n",
      "158 layer3.0.bn3.bias torch.Size([1024])\n",
      "159 layer3.0.bn3.running_mean torch.Size([1024])\n",
      "160 layer3.0.bn3.running_var torch.Size([1024])\n",
      "161 layer3.0.bn3.num_batches_tracked torch.Size([])\n",
      "162 layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "163 layer3.0.downsample.1.weight torch.Size([1024])\n",
      "164 layer3.0.downsample.1.bias torch.Size([1024])\n",
      "165 layer3.0.downsample.1.running_mean torch.Size([1024])\n",
      "166 layer3.0.downsample.1.running_var torch.Size([1024])\n",
      "167 layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "168 layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "169 layer3.1.bn1.weight torch.Size([256])\n",
      "170 layer3.1.bn1.bias torch.Size([256])\n",
      "171 layer3.1.bn1.running_mean torch.Size([256])\n",
      "172 layer3.1.bn1.running_var torch.Size([256])\n",
      "173 layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "174 layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "175 layer3.1.bn2.weight torch.Size([256])\n",
      "176 layer3.1.bn2.bias torch.Size([256])\n",
      "177 layer3.1.bn2.running_mean torch.Size([256])\n",
      "178 layer3.1.bn2.running_var torch.Size([256])\n",
      "179 layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "180 layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "181 layer3.1.bn3.weight torch.Size([1024])\n",
      "182 layer3.1.bn3.bias torch.Size([1024])\n",
      "183 layer3.1.bn3.running_mean torch.Size([1024])\n",
      "184 layer3.1.bn3.running_var torch.Size([1024])\n",
      "185 layer3.1.bn3.num_batches_tracked torch.Size([])\n",
      "186 layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "187 layer3.2.bn1.weight torch.Size([256])\n",
      "188 layer3.2.bn1.bias torch.Size([256])\n",
      "189 layer3.2.bn1.running_mean torch.Size([256])\n",
      "190 layer3.2.bn1.running_var torch.Size([256])\n",
      "191 layer3.2.bn1.num_batches_tracked torch.Size([])\n",
      "192 layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "193 layer3.2.bn2.weight torch.Size([256])\n",
      "194 layer3.2.bn2.bias torch.Size([256])\n",
      "195 layer3.2.bn2.running_mean torch.Size([256])\n",
      "196 layer3.2.bn2.running_var torch.Size([256])\n",
      "197 layer3.2.bn2.num_batches_tracked torch.Size([])\n",
      "198 layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "199 layer3.2.bn3.weight torch.Size([1024])\n",
      "200 layer3.2.bn3.bias torch.Size([1024])\n",
      "201 layer3.2.bn3.running_mean torch.Size([1024])\n",
      "202 layer3.2.bn3.running_var torch.Size([1024])\n",
      "203 layer3.2.bn3.num_batches_tracked torch.Size([])\n",
      "204 layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "205 layer3.3.bn1.weight torch.Size([256])\n",
      "206 layer3.3.bn1.bias torch.Size([256])\n",
      "207 layer3.3.bn1.running_mean torch.Size([256])\n",
      "208 layer3.3.bn1.running_var torch.Size([256])\n",
      "209 layer3.3.bn1.num_batches_tracked torch.Size([])\n",
      "210 layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "211 layer3.3.bn2.weight torch.Size([256])\n",
      "212 layer3.3.bn2.bias torch.Size([256])\n",
      "213 layer3.3.bn2.running_mean torch.Size([256])\n",
      "214 layer3.3.bn2.running_var torch.Size([256])\n",
      "215 layer3.3.bn2.num_batches_tracked torch.Size([])\n",
      "216 layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "217 layer3.3.bn3.weight torch.Size([1024])\n",
      "218 layer3.3.bn3.bias torch.Size([1024])\n",
      "219 layer3.3.bn3.running_mean torch.Size([1024])\n",
      "220 layer3.3.bn3.running_var torch.Size([1024])\n",
      "221 layer3.3.bn3.num_batches_tracked torch.Size([])\n",
      "222 layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "223 layer3.4.bn1.weight torch.Size([256])\n",
      "224 layer3.4.bn1.bias torch.Size([256])\n",
      "225 layer3.4.bn1.running_mean torch.Size([256])\n",
      "226 layer3.4.bn1.running_var torch.Size([256])\n",
      "227 layer3.4.bn1.num_batches_tracked torch.Size([])\n",
      "228 layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "229 layer3.4.bn2.weight torch.Size([256])\n",
      "230 layer3.4.bn2.bias torch.Size([256])\n",
      "231 layer3.4.bn2.running_mean torch.Size([256])\n",
      "232 layer3.4.bn2.running_var torch.Size([256])\n",
      "233 layer3.4.bn2.num_batches_tracked torch.Size([])\n",
      "234 layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "235 layer3.4.bn3.weight torch.Size([1024])\n",
      "236 layer3.4.bn3.bias torch.Size([1024])\n",
      "237 layer3.4.bn3.running_mean torch.Size([1024])\n",
      "238 layer3.4.bn3.running_var torch.Size([1024])\n",
      "239 layer3.4.bn3.num_batches_tracked torch.Size([])\n",
      "240 layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "241 layer3.5.bn1.weight torch.Size([256])\n",
      "242 layer3.5.bn1.bias torch.Size([256])\n",
      "243 layer3.5.bn1.running_mean torch.Size([256])\n",
      "244 layer3.5.bn1.running_var torch.Size([256])\n",
      "245 layer3.5.bn1.num_batches_tracked torch.Size([])\n",
      "246 layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "247 layer3.5.bn2.weight torch.Size([256])\n",
      "248 layer3.5.bn2.bias torch.Size([256])\n",
      "249 layer3.5.bn2.running_mean torch.Size([256])\n",
      "250 layer3.5.bn2.running_var torch.Size([256])\n",
      "251 layer3.5.bn2.num_batches_tracked torch.Size([])\n",
      "252 layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "253 layer3.5.bn3.weight torch.Size([1024])\n",
      "254 layer3.5.bn3.bias torch.Size([1024])\n",
      "255 layer3.5.bn3.running_mean torch.Size([1024])\n",
      "256 layer3.5.bn3.running_var torch.Size([1024])\n",
      "257 layer3.5.bn3.num_batches_tracked torch.Size([])\n",
      "258 layer4.0.conv1_u.weight torch.Size([128, 1024, 1, 1])\n",
      "259 layer4.0.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "260 layer4.0.bn1.weight torch.Size([512])\n",
      "261 layer4.0.bn1.bias torch.Size([512])\n",
      "262 layer4.0.bn1.running_mean torch.Size([512])\n",
      "263 layer4.0.bn1.running_var torch.Size([512])\n",
      "264 layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "265 layer4.0.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "266 layer4.0.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "267 layer4.0.bn2.weight torch.Size([512])\n",
      "268 layer4.0.bn2.bias torch.Size([512])\n",
      "269 layer4.0.bn2.running_mean torch.Size([512])\n",
      "270 layer4.0.bn2.running_var torch.Size([512])\n",
      "271 layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "272 layer4.0.conv3_u.weight torch.Size([128, 512, 1, 1])\n",
      "273 layer4.0.conv3_v.weight torch.Size([2048, 128, 1, 1])\n",
      "274 layer4.0.bn3.weight torch.Size([2048])\n",
      "275 layer4.0.bn3.bias torch.Size([2048])\n",
      "276 layer4.0.bn3.running_mean torch.Size([2048])\n",
      "277 layer4.0.bn3.running_var torch.Size([2048])\n",
      "278 layer4.0.bn3.num_batches_tracked torch.Size([])\n",
      "279 layer4.0.downsample.0.weight torch.Size([256, 1024, 1, 1])\n",
      "280 layer4.0.downsample.1.weight torch.Size([2048, 256, 1, 1])\n",
      "281 layer4.0.downsample.2.weight torch.Size([2048])\n",
      "282 layer4.0.downsample.2.bias torch.Size([2048])\n",
      "283 layer4.0.downsample.2.running_mean torch.Size([2048])\n",
      "284 layer4.0.downsample.2.running_var torch.Size([2048])\n",
      "285 layer4.0.downsample.2.num_batches_tracked torch.Size([])\n",
      "286 layer4.1.conv1_u.weight torch.Size([128, 2048, 1, 1])\n",
      "287 layer4.1.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "288 layer4.1.bn1.weight torch.Size([512])\n",
      "289 layer4.1.bn1.bias torch.Size([512])\n",
      "290 layer4.1.bn1.running_mean torch.Size([512])\n",
      "291 layer4.1.bn1.running_var torch.Size([512])\n",
      "292 layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "293 layer4.1.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "294 layer4.1.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "295 layer4.1.bn2.weight torch.Size([512])\n",
      "296 layer4.1.bn2.bias torch.Size([512])\n",
      "297 layer4.1.bn2.running_mean torch.Size([512])\n",
      "298 layer4.1.bn2.running_var torch.Size([512])\n",
      "299 layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "300 layer4.1.conv3_u.weight torch.Size([128, 512, 1, 1])\n",
      "301 layer4.1.conv3_v.weight torch.Size([2048, 128, 1, 1])\n",
      "302 layer4.1.bn3.weight torch.Size([2048])\n",
      "303 layer4.1.bn3.bias torch.Size([2048])\n",
      "304 layer4.1.bn3.running_mean torch.Size([2048])\n",
      "305 layer4.1.bn3.running_var torch.Size([2048])\n",
      "306 layer4.1.bn3.num_batches_tracked torch.Size([])\n",
      "307 layer4.2.conv1_u.weight torch.Size([128, 2048, 1, 1])\n",
      "308 layer4.2.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "309 layer4.2.bn1.weight torch.Size([512])\n",
      "310 layer4.2.bn1.bias torch.Size([512])\n",
      "311 layer4.2.bn1.running_mean torch.Size([512])\n",
      "312 layer4.2.bn1.running_var torch.Size([512])\n",
      "313 layer4.2.bn1.num_batches_tracked torch.Size([])\n",
      "314 layer4.2.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "315 layer4.2.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "316 layer4.2.bn2.weight torch.Size([512])\n",
      "317 layer4.2.bn2.bias torch.Size([512])\n",
      "318 layer4.2.bn2.running_mean torch.Size([512])\n",
      "319 layer4.2.bn2.running_var torch.Size([512])\n",
      "320 layer4.2.bn2.num_batches_tracked torch.Size([])\n",
      "321 layer4.2.conv3_u.weight torch.Size([128, 512, 1, 1])\n",
      "322 layer4.2.conv3_v.weight torch.Size([2048, 128, 1, 1])\n",
      "323 layer4.2.bn3.weight torch.Size([2048])\n",
      "324 layer4.2.bn3.bias torch.Size([2048])\n",
      "325 layer4.2.bn3.running_mean torch.Size([2048])\n",
      "326 layer4.2.bn3.running_var torch.Size([2048])\n",
      "327 layer4.2.bn3.num_batches_tracked torch.Size([])\n",
      "328 fc.weight torch.Size([1000, 2048])\n",
      "329 fc.bias torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 7, 7])\n",
      "1 bn1.weight torch.Size([64])\n",
      "2 bn1.bias torch.Size([64])\n",
      "3 bn1.running_mean torch.Size([64])\n",
      "4 bn1.running_var torch.Size([64])\n",
      "5 bn1.num_batches_tracked torch.Size([])\n",
      "6 layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "7 layer1.0.bn1.weight torch.Size([64])\n",
      "8 layer1.0.bn1.bias torch.Size([64])\n",
      "9 layer1.0.bn1.running_mean torch.Size([64])\n",
      "10 layer1.0.bn1.running_var torch.Size([64])\n",
      "11 layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "12 layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "13 layer1.0.bn2.weight torch.Size([64])\n",
      "14 layer1.0.bn2.bias torch.Size([64])\n",
      "15 layer1.0.bn2.running_mean torch.Size([64])\n",
      "16 layer1.0.bn2.running_var torch.Size([64])\n",
      "17 layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "18 layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "19 layer1.0.bn3.weight torch.Size([256])\n",
      "20 layer1.0.bn3.bias torch.Size([256])\n",
      "21 layer1.0.bn3.running_mean torch.Size([256])\n",
      "22 layer1.0.bn3.running_var torch.Size([256])\n",
      "23 layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "24 layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "25 layer1.0.downsample.1.weight torch.Size([256])\n",
      "26 layer1.0.downsample.1.bias torch.Size([256])\n",
      "27 layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "28 layer1.0.downsample.1.running_var torch.Size([256])\n",
      "29 layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "30 layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "31 layer1.1.bn1.weight torch.Size([64])\n",
      "32 layer1.1.bn1.bias torch.Size([64])\n",
      "33 layer1.1.bn1.running_mean torch.Size([64])\n",
      "34 layer1.1.bn1.running_var torch.Size([64])\n",
      "35 layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "36 layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "37 layer1.1.bn2.weight torch.Size([64])\n",
      "38 layer1.1.bn2.bias torch.Size([64])\n",
      "39 layer1.1.bn2.running_mean torch.Size([64])\n",
      "40 layer1.1.bn2.running_var torch.Size([64])\n",
      "41 layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "42 layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "43 layer1.1.bn3.weight torch.Size([256])\n",
      "44 layer1.1.bn3.bias torch.Size([256])\n",
      "45 layer1.1.bn3.running_mean torch.Size([256])\n",
      "46 layer1.1.bn3.running_var torch.Size([256])\n",
      "47 layer1.1.bn3.num_batches_tracked torch.Size([])\n",
      "48 layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "49 layer1.2.bn1.weight torch.Size([64])\n",
      "50 layer1.2.bn1.bias torch.Size([64])\n",
      "51 layer1.2.bn1.running_mean torch.Size([64])\n",
      "52 layer1.2.bn1.running_var torch.Size([64])\n",
      "53 layer1.2.bn1.num_batches_tracked torch.Size([])\n",
      "54 layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "55 layer1.2.bn2.weight torch.Size([64])\n",
      "56 layer1.2.bn2.bias torch.Size([64])\n",
      "57 layer1.2.bn2.running_mean torch.Size([64])\n",
      "58 layer1.2.bn2.running_var torch.Size([64])\n",
      "59 layer1.2.bn2.num_batches_tracked torch.Size([])\n",
      "60 layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "61 layer1.2.bn3.weight torch.Size([256])\n",
      "62 layer1.2.bn3.bias torch.Size([256])\n",
      "63 layer1.2.bn3.running_mean torch.Size([256])\n",
      "64 layer1.2.bn3.running_var torch.Size([256])\n",
      "65 layer1.2.bn3.num_batches_tracked torch.Size([])\n",
      "66 layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "67 layer2.0.bn1.weight torch.Size([128])\n",
      "68 layer2.0.bn1.bias torch.Size([128])\n",
      "69 layer2.0.bn1.running_mean torch.Size([128])\n",
      "70 layer2.0.bn1.running_var torch.Size([128])\n",
      "71 layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "72 layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "73 layer2.0.bn2.weight torch.Size([128])\n",
      "74 layer2.0.bn2.bias torch.Size([128])\n",
      "75 layer2.0.bn2.running_mean torch.Size([128])\n",
      "76 layer2.0.bn2.running_var torch.Size([128])\n",
      "77 layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "78 layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "79 layer2.0.bn3.weight torch.Size([512])\n",
      "80 layer2.0.bn3.bias torch.Size([512])\n",
      "81 layer2.0.bn3.running_mean torch.Size([512])\n",
      "82 layer2.0.bn3.running_var torch.Size([512])\n",
      "83 layer2.0.bn3.num_batches_tracked torch.Size([])\n",
      "84 layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "85 layer2.0.downsample.1.weight torch.Size([512])\n",
      "86 layer2.0.downsample.1.bias torch.Size([512])\n",
      "87 layer2.0.downsample.1.running_mean torch.Size([512])\n",
      "88 layer2.0.downsample.1.running_var torch.Size([512])\n",
      "89 layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "90 layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "91 layer2.1.bn1.weight torch.Size([128])\n",
      "92 layer2.1.bn1.bias torch.Size([128])\n",
      "93 layer2.1.bn1.running_mean torch.Size([128])\n",
      "94 layer2.1.bn1.running_var torch.Size([128])\n",
      "95 layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "96 layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "97 layer2.1.bn2.weight torch.Size([128])\n",
      "98 layer2.1.bn2.bias torch.Size([128])\n",
      "99 layer2.1.bn2.running_mean torch.Size([128])\n",
      "100 layer2.1.bn2.running_var torch.Size([128])\n",
      "101 layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "102 layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "103 layer2.1.bn3.weight torch.Size([512])\n",
      "104 layer2.1.bn3.bias torch.Size([512])\n",
      "105 layer2.1.bn3.running_mean torch.Size([512])\n",
      "106 layer2.1.bn3.running_var torch.Size([512])\n",
      "107 layer2.1.bn3.num_batches_tracked torch.Size([])\n",
      "108 layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "109 layer2.2.bn1.weight torch.Size([128])\n",
      "110 layer2.2.bn1.bias torch.Size([128])\n",
      "111 layer2.2.bn1.running_mean torch.Size([128])\n",
      "112 layer2.2.bn1.running_var torch.Size([128])\n",
      "113 layer2.2.bn1.num_batches_tracked torch.Size([])\n",
      "114 layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "115 layer2.2.bn2.weight torch.Size([128])\n",
      "116 layer2.2.bn2.bias torch.Size([128])\n",
      "117 layer2.2.bn2.running_mean torch.Size([128])\n",
      "118 layer2.2.bn2.running_var torch.Size([128])\n",
      "119 layer2.2.bn2.num_batches_tracked torch.Size([])\n",
      "120 layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "121 layer2.2.bn3.weight torch.Size([512])\n",
      "122 layer2.2.bn3.bias torch.Size([512])\n",
      "123 layer2.2.bn3.running_mean torch.Size([512])\n",
      "124 layer2.2.bn3.running_var torch.Size([512])\n",
      "125 layer2.2.bn3.num_batches_tracked torch.Size([])\n",
      "126 layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "127 layer2.3.bn1.weight torch.Size([128])\n",
      "128 layer2.3.bn1.bias torch.Size([128])\n",
      "129 layer2.3.bn1.running_mean torch.Size([128])\n",
      "130 layer2.3.bn1.running_var torch.Size([128])\n",
      "131 layer2.3.bn1.num_batches_tracked torch.Size([])\n",
      "132 layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "133 layer2.3.bn2.weight torch.Size([128])\n",
      "134 layer2.3.bn2.bias torch.Size([128])\n",
      "135 layer2.3.bn2.running_mean torch.Size([128])\n",
      "136 layer2.3.bn2.running_var torch.Size([128])\n",
      "137 layer2.3.bn2.num_batches_tracked torch.Size([])\n",
      "138 layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "139 layer2.3.bn3.weight torch.Size([512])\n",
      "140 layer2.3.bn3.bias torch.Size([512])\n",
      "141 layer2.3.bn3.running_mean torch.Size([512])\n",
      "142 layer2.3.bn3.running_var torch.Size([512])\n",
      "143 layer2.3.bn3.num_batches_tracked torch.Size([])\n",
      "144 layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "145 layer3.0.bn1.weight torch.Size([256])\n",
      "146 layer3.0.bn1.bias torch.Size([256])\n",
      "147 layer3.0.bn1.running_mean torch.Size([256])\n",
      "148 layer3.0.bn1.running_var torch.Size([256])\n",
      "149 layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "150 layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "151 layer3.0.bn2.weight torch.Size([256])\n",
      "152 layer3.0.bn2.bias torch.Size([256])\n",
      "153 layer3.0.bn2.running_mean torch.Size([256])\n",
      "154 layer3.0.bn2.running_var torch.Size([256])\n",
      "155 layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "156 layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "157 layer3.0.bn3.weight torch.Size([1024])\n",
      "158 layer3.0.bn3.bias torch.Size([1024])\n",
      "159 layer3.0.bn3.running_mean torch.Size([1024])\n",
      "160 layer3.0.bn3.running_var torch.Size([1024])\n",
      "161 layer3.0.bn3.num_batches_tracked torch.Size([])\n",
      "162 layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "163 layer3.0.downsample.1.weight torch.Size([1024])\n",
      "164 layer3.0.downsample.1.bias torch.Size([1024])\n",
      "165 layer3.0.downsample.1.running_mean torch.Size([1024])\n",
      "166 layer3.0.downsample.1.running_var torch.Size([1024])\n",
      "167 layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "168 layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "169 layer3.1.bn1.weight torch.Size([256])\n",
      "170 layer3.1.bn1.bias torch.Size([256])\n",
      "171 layer3.1.bn1.running_mean torch.Size([256])\n",
      "172 layer3.1.bn1.running_var torch.Size([256])\n",
      "173 layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "174 layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "175 layer3.1.bn2.weight torch.Size([256])\n",
      "176 layer3.1.bn2.bias torch.Size([256])\n",
      "177 layer3.1.bn2.running_mean torch.Size([256])\n",
      "178 layer3.1.bn2.running_var torch.Size([256])\n",
      "179 layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "180 layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "181 layer3.1.bn3.weight torch.Size([1024])\n",
      "182 layer3.1.bn3.bias torch.Size([1024])\n",
      "183 layer3.1.bn3.running_mean torch.Size([1024])\n",
      "184 layer3.1.bn3.running_var torch.Size([1024])\n",
      "185 layer3.1.bn3.num_batches_tracked torch.Size([])\n",
      "186 layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "187 layer3.2.bn1.weight torch.Size([256])\n",
      "188 layer3.2.bn1.bias torch.Size([256])\n",
      "189 layer3.2.bn1.running_mean torch.Size([256])\n",
      "190 layer3.2.bn1.running_var torch.Size([256])\n",
      "191 layer3.2.bn1.num_batches_tracked torch.Size([])\n",
      "192 layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "193 layer3.2.bn2.weight torch.Size([256])\n",
      "194 layer3.2.bn2.bias torch.Size([256])\n",
      "195 layer3.2.bn2.running_mean torch.Size([256])\n",
      "196 layer3.2.bn2.running_var torch.Size([256])\n",
      "197 layer3.2.bn2.num_batches_tracked torch.Size([])\n",
      "198 layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "199 layer3.2.bn3.weight torch.Size([1024])\n",
      "200 layer3.2.bn3.bias torch.Size([1024])\n",
      "201 layer3.2.bn3.running_mean torch.Size([1024])\n",
      "202 layer3.2.bn3.running_var torch.Size([1024])\n",
      "203 layer3.2.bn3.num_batches_tracked torch.Size([])\n",
      "204 layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "205 layer3.3.bn1.weight torch.Size([256])\n",
      "206 layer3.3.bn1.bias torch.Size([256])\n",
      "207 layer3.3.bn1.running_mean torch.Size([256])\n",
      "208 layer3.3.bn1.running_var torch.Size([256])\n",
      "209 layer3.3.bn1.num_batches_tracked torch.Size([])\n",
      "210 layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "211 layer3.3.bn2.weight torch.Size([256])\n",
      "212 layer3.3.bn2.bias torch.Size([256])\n",
      "213 layer3.3.bn2.running_mean torch.Size([256])\n",
      "214 layer3.3.bn2.running_var torch.Size([256])\n",
      "215 layer3.3.bn2.num_batches_tracked torch.Size([])\n",
      "216 layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "217 layer3.3.bn3.weight torch.Size([1024])\n",
      "218 layer3.3.bn3.bias torch.Size([1024])\n",
      "219 layer3.3.bn3.running_mean torch.Size([1024])\n",
      "220 layer3.3.bn3.running_var torch.Size([1024])\n",
      "221 layer3.3.bn3.num_batches_tracked torch.Size([])\n",
      "222 layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "223 layer3.4.bn1.weight torch.Size([256])\n",
      "224 layer3.4.bn1.bias torch.Size([256])\n",
      "225 layer3.4.bn1.running_mean torch.Size([256])\n",
      "226 layer3.4.bn1.running_var torch.Size([256])\n",
      "227 layer3.4.bn1.num_batches_tracked torch.Size([])\n",
      "228 layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "229 layer3.4.bn2.weight torch.Size([256])\n",
      "230 layer3.4.bn2.bias torch.Size([256])\n",
      "231 layer3.4.bn2.running_mean torch.Size([256])\n",
      "232 layer3.4.bn2.running_var torch.Size([256])\n",
      "233 layer3.4.bn2.num_batches_tracked torch.Size([])\n",
      "234 layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "235 layer3.4.bn3.weight torch.Size([1024])\n",
      "236 layer3.4.bn3.bias torch.Size([1024])\n",
      "237 layer3.4.bn3.running_mean torch.Size([1024])\n",
      "238 layer3.4.bn3.running_var torch.Size([1024])\n",
      "239 layer3.4.bn3.num_batches_tracked torch.Size([])\n",
      "240 layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "241 layer3.5.bn1.weight torch.Size([256])\n",
      "242 layer3.5.bn1.bias torch.Size([256])\n",
      "243 layer3.5.bn1.running_mean torch.Size([256])\n",
      "244 layer3.5.bn1.running_var torch.Size([256])\n",
      "245 layer3.5.bn1.num_batches_tracked torch.Size([])\n",
      "246 layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "247 layer3.5.bn2.weight torch.Size([256])\n",
      "248 layer3.5.bn2.bias torch.Size([256])\n",
      "249 layer3.5.bn2.running_mean torch.Size([256])\n",
      "250 layer3.5.bn2.running_var torch.Size([256])\n",
      "251 layer3.5.bn2.num_batches_tracked torch.Size([])\n",
      "252 layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "253 layer3.5.bn3.weight torch.Size([1024])\n",
      "254 layer3.5.bn3.bias torch.Size([1024])\n",
      "255 layer3.5.bn3.running_mean torch.Size([1024])\n",
      "256 layer3.5.bn3.running_var torch.Size([1024])\n",
      "257 layer3.5.bn3.num_batches_tracked torch.Size([])\n",
      "258 layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "259 layer4.0.bn1.weight torch.Size([512])\n",
      "260 layer4.0.bn1.bias torch.Size([512])\n",
      "261 layer4.0.bn1.running_mean torch.Size([512])\n",
      "262 layer4.0.bn1.running_var torch.Size([512])\n",
      "263 layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "264 layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "265 layer4.0.bn2.weight torch.Size([512])\n",
      "266 layer4.0.bn2.bias torch.Size([512])\n",
      "267 layer4.0.bn2.running_mean torch.Size([512])\n",
      "268 layer4.0.bn2.running_var torch.Size([512])\n",
      "269 layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "270 layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "271 layer4.0.bn3.weight torch.Size([2048])\n",
      "272 layer4.0.bn3.bias torch.Size([2048])\n",
      "273 layer4.0.bn3.running_mean torch.Size([2048])\n",
      "274 layer4.0.bn3.running_var torch.Size([2048])\n",
      "275 layer4.0.bn3.num_batches_tracked torch.Size([])\n",
      "276 layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "277 layer4.0.downsample.1.weight torch.Size([2048])\n",
      "278 layer4.0.downsample.1.bias torch.Size([2048])\n",
      "279 layer4.0.downsample.1.running_mean torch.Size([2048])\n",
      "280 layer4.0.downsample.1.running_var torch.Size([2048])\n",
      "281 layer4.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "282 layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "283 layer4.1.bn1.weight torch.Size([512])\n",
      "284 layer4.1.bn1.bias torch.Size([512])\n",
      "285 layer4.1.bn1.running_mean torch.Size([512])\n",
      "286 layer4.1.bn1.running_var torch.Size([512])\n",
      "287 layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "288 layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "289 layer4.1.bn2.weight torch.Size([512])\n",
      "290 layer4.1.bn2.bias torch.Size([512])\n",
      "291 layer4.1.bn2.running_mean torch.Size([512])\n",
      "292 layer4.1.bn2.running_var torch.Size([512])\n",
      "293 layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "294 layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "295 layer4.1.bn3.weight torch.Size([2048])\n",
      "296 layer4.1.bn3.bias torch.Size([2048])\n",
      "297 layer4.1.bn3.running_mean torch.Size([2048])\n",
      "298 layer4.1.bn3.running_var torch.Size([2048])\n",
      "299 layer4.1.bn3.num_batches_tracked torch.Size([])\n",
      "300 layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "301 layer4.2.bn1.weight torch.Size([512])\n",
      "302 layer4.2.bn1.bias torch.Size([512])\n",
      "303 layer4.2.bn1.running_mean torch.Size([512])\n",
      "304 layer4.2.bn1.running_var torch.Size([512])\n",
      "305 layer4.2.bn1.num_batches_tracked torch.Size([])\n",
      "306 layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "307 layer4.2.bn2.weight torch.Size([512])\n",
      "308 layer4.2.bn2.bias torch.Size([512])\n",
      "309 layer4.2.bn2.running_mean torch.Size([512])\n",
      "310 layer4.2.bn2.running_var torch.Size([512])\n",
      "311 layer4.2.bn2.num_batches_tracked torch.Size([])\n",
      "312 layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "313 layer4.2.bn3.weight torch.Size([2048])\n",
      "314 layer4.2.bn3.bias torch.Size([2048])\n",
      "315 layer4.2.bn3.running_mean torch.Size([2048])\n",
      "316 layer4.2.bn3.running_var torch.Size([2048])\n",
      "317 layer4.2.bn3.num_batches_tracked torch.Size([])\n",
      "318 fc.weight torch.Size([1000, 2048])\n",
      "319 fc.bias torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(vanilla_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model decomposition for low rank VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lowrank_vgg import LowRankVGG, FullRankVGG, FullRankVGG19, LowRankVGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rank_model = FullRankVGG19()\n",
    "low_rank_model = LowRankVGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 3, 3])\n",
      "1 batch_norm1.weight torch.Size([64])\n",
      "2 batch_norm1.bias torch.Size([64])\n",
      "3 batch_norm1.running_mean torch.Size([64])\n",
      "4 batch_norm1.running_var torch.Size([64])\n",
      "5 batch_norm1.num_batches_tracked torch.Size([])\n",
      "6 conv2.weight torch.Size([64, 64, 3, 3])\n",
      "7 batch_norm2.weight torch.Size([64])\n",
      "8 batch_norm2.bias torch.Size([64])\n",
      "9 batch_norm2.running_mean torch.Size([64])\n",
      "10 batch_norm2.running_var torch.Size([64])\n",
      "11 batch_norm2.num_batches_tracked torch.Size([])\n",
      "12 conv3.weight torch.Size([128, 64, 3, 3])\n",
      "13 batch_norm3.weight torch.Size([128])\n",
      "14 batch_norm3.bias torch.Size([128])\n",
      "15 batch_norm3.running_mean torch.Size([128])\n",
      "16 batch_norm3.running_var torch.Size([128])\n",
      "17 batch_norm3.num_batches_tracked torch.Size([])\n",
      "18 conv4.weight torch.Size([128, 128, 3, 3])\n",
      "19 batch_norm4.weight torch.Size([128])\n",
      "20 batch_norm4.bias torch.Size([128])\n",
      "21 batch_norm4.running_mean torch.Size([128])\n",
      "22 batch_norm4.running_var torch.Size([128])\n",
      "23 batch_norm4.num_batches_tracked torch.Size([])\n",
      "24 conv5.weight torch.Size([256, 128, 3, 3])\n",
      "25 batch_norm5.weight torch.Size([256])\n",
      "26 batch_norm5.bias torch.Size([256])\n",
      "27 batch_norm5.running_mean torch.Size([256])\n",
      "28 batch_norm5.running_var torch.Size([256])\n",
      "29 batch_norm5.num_batches_tracked torch.Size([])\n",
      "30 conv6.weight torch.Size([256, 256, 3, 3])\n",
      "31 batch_norm6.weight torch.Size([256])\n",
      "32 batch_norm6.bias torch.Size([256])\n",
      "33 batch_norm6.running_mean torch.Size([256])\n",
      "34 batch_norm6.running_var torch.Size([256])\n",
      "35 batch_norm6.num_batches_tracked torch.Size([])\n",
      "36 conv7.weight torch.Size([256, 256, 3, 3])\n",
      "37 batch_norm7.weight torch.Size([256])\n",
      "38 batch_norm7.bias torch.Size([256])\n",
      "39 batch_norm7.running_mean torch.Size([256])\n",
      "40 batch_norm7.running_var torch.Size([256])\n",
      "41 batch_norm7.num_batches_tracked torch.Size([])\n",
      "42 conv8.weight torch.Size([256, 256, 3, 3])\n",
      "43 batch_norm8.weight torch.Size([256])\n",
      "44 batch_norm8.bias torch.Size([256])\n",
      "45 batch_norm8.running_mean torch.Size([256])\n",
      "46 batch_norm8.running_var torch.Size([256])\n",
      "47 batch_norm8.num_batches_tracked torch.Size([])\n",
      "48 conv9.weight torch.Size([512, 256, 3, 3])\n",
      "49 batch_norm9.weight torch.Size([512])\n",
      "50 batch_norm9.bias torch.Size([512])\n",
      "51 batch_norm9.running_mean torch.Size([512])\n",
      "52 batch_norm9.running_var torch.Size([512])\n",
      "53 batch_norm9.num_batches_tracked torch.Size([])\n",
      "54 conv10.weight torch.Size([512, 512, 3, 3])\n",
      "55 batch_norm10.weight torch.Size([512])\n",
      "56 batch_norm10.bias torch.Size([512])\n",
      "57 batch_norm10.running_mean torch.Size([512])\n",
      "58 batch_norm10.running_var torch.Size([512])\n",
      "59 batch_norm10.num_batches_tracked torch.Size([])\n",
      "60 conv11.weight torch.Size([512, 512, 3, 3])\n",
      "61 batch_norm11.weight torch.Size([512])\n",
      "62 batch_norm11.bias torch.Size([512])\n",
      "63 batch_norm11.running_mean torch.Size([512])\n",
      "64 batch_norm11.running_var torch.Size([512])\n",
      "65 batch_norm11.num_batches_tracked torch.Size([])\n",
      "66 conv12.weight torch.Size([512, 512, 3, 3])\n",
      "67 batch_norm12.weight torch.Size([512])\n",
      "68 batch_norm12.bias torch.Size([512])\n",
      "69 batch_norm12.running_mean torch.Size([512])\n",
      "70 batch_norm12.running_var torch.Size([512])\n",
      "71 batch_norm12.num_batches_tracked torch.Size([])\n",
      "72 conv13.weight torch.Size([512, 512, 3, 3])\n",
      "73 batch_norm13.weight torch.Size([512])\n",
      "74 batch_norm13.bias torch.Size([512])\n",
      "75 batch_norm13.running_mean torch.Size([512])\n",
      "76 batch_norm13.running_var torch.Size([512])\n",
      "77 batch_norm13.num_batches_tracked torch.Size([])\n",
      "78 conv14.weight torch.Size([512, 512, 3, 3])\n",
      "79 batch_norm14.weight torch.Size([512])\n",
      "80 batch_norm14.bias torch.Size([512])\n",
      "81 batch_norm14.running_mean torch.Size([512])\n",
      "82 batch_norm14.running_var torch.Size([512])\n",
      "83 batch_norm14.num_batches_tracked torch.Size([])\n",
      "84 conv15.weight torch.Size([512, 512, 3, 3])\n",
      "85 batch_norm15.weight torch.Size([512])\n",
      "86 batch_norm15.bias torch.Size([512])\n",
      "87 batch_norm15.running_mean torch.Size([512])\n",
      "88 batch_norm15.running_var torch.Size([512])\n",
      "89 batch_norm15.num_batches_tracked torch.Size([])\n",
      "90 conv16.weight torch.Size([512, 512, 3, 3])\n",
      "91 batch_norm16.weight torch.Size([512])\n",
      "92 batch_norm16.bias torch.Size([512])\n",
      "93 batch_norm16.running_mean torch.Size([512])\n",
      "94 batch_norm16.running_var torch.Size([512])\n",
      "95 batch_norm16.num_batches_tracked torch.Size([])\n",
      "96 classifier.1.weight torch.Size([512, 512])\n",
      "97 classifier.1.bias torch.Size([512])\n",
      "98 classifier.4.weight torch.Size([512, 512])\n",
      "99 classifier.4.bias torch.Size([512])\n",
      "100 classifier.6.weight torch.Size([10, 512])\n",
      "101 classifier.6.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(full_rank_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 3, 3])\n",
      "1 batch_norm1.weight torch.Size([64])\n",
      "2 batch_norm1.bias torch.Size([64])\n",
      "3 batch_norm1.running_mean torch.Size([64])\n",
      "4 batch_norm1.running_var torch.Size([64])\n",
      "5 batch_norm1.num_batches_tracked torch.Size([])\n",
      "6 conv2.weight torch.Size([64, 64, 3, 3])\n",
      "7 batch_norm2.weight torch.Size([64])\n",
      "8 batch_norm2.bias torch.Size([64])\n",
      "9 batch_norm2.running_mean torch.Size([64])\n",
      "10 batch_norm2.running_var torch.Size([64])\n",
      "11 batch_norm2.num_batches_tracked torch.Size([])\n",
      "12 conv3.weight torch.Size([128, 64, 3, 3])\n",
      "13 batch_norm3.weight torch.Size([128])\n",
      "14 batch_norm3.bias torch.Size([128])\n",
      "15 batch_norm3.running_mean torch.Size([128])\n",
      "16 batch_norm3.running_var torch.Size([128])\n",
      "17 batch_norm3.num_batches_tracked torch.Size([])\n",
      "18 conv4.weight torch.Size([128, 128, 3, 3])\n",
      "19 batch_norm4.weight torch.Size([128])\n",
      "20 batch_norm4.bias torch.Size([128])\n",
      "21 batch_norm4.running_mean torch.Size([128])\n",
      "22 batch_norm4.running_var torch.Size([128])\n",
      "23 batch_norm4.num_batches_tracked torch.Size([])\n",
      "24 conv5.weight torch.Size([256, 128, 3, 3])\n",
      "25 batch_norm5.weight torch.Size([256])\n",
      "26 batch_norm5.bias torch.Size([256])\n",
      "27 batch_norm5.running_mean torch.Size([256])\n",
      "28 batch_norm5.running_var torch.Size([256])\n",
      "29 batch_norm5.num_batches_tracked torch.Size([])\n",
      "30 conv6.weight torch.Size([256, 256, 3, 3])\n",
      "31 batch_norm6.weight torch.Size([256])\n",
      "32 batch_norm6.bias torch.Size([256])\n",
      "33 batch_norm6.running_mean torch.Size([256])\n",
      "34 batch_norm6.running_var torch.Size([256])\n",
      "35 batch_norm6.num_batches_tracked torch.Size([])\n",
      "36 conv7.weight torch.Size([256, 256, 3, 3])\n",
      "37 batch_norm7.weight torch.Size([256])\n",
      "38 batch_norm7.bias torch.Size([256])\n",
      "39 batch_norm7.running_mean torch.Size([256])\n",
      "40 batch_norm7.running_var torch.Size([256])\n",
      "41 batch_norm7.num_batches_tracked torch.Size([])\n",
      "42 conv8.weight torch.Size([256, 256, 3, 3])\n",
      "43 batch_norm8.weight torch.Size([256])\n",
      "44 batch_norm8.bias torch.Size([256])\n",
      "45 batch_norm8.running_mean torch.Size([256])\n",
      "46 batch_norm8.running_var torch.Size([256])\n",
      "47 batch_norm8.num_batches_tracked torch.Size([])\n",
      "48 conv9.weight torch.Size([512, 256, 3, 3])\n",
      "49 batch_norm9.weight torch.Size([512])\n",
      "50 batch_norm9.bias torch.Size([512])\n",
      "51 batch_norm9.running_mean torch.Size([512])\n",
      "52 batch_norm9.running_var torch.Size([512])\n",
      "53 batch_norm9.num_batches_tracked torch.Size([])\n",
      "54 conv10_u.weight torch.Size([128, 512, 3, 3])\n",
      "55 conv10_v.weight torch.Size([512, 128, 1, 1])\n",
      "56 batch_norm10.weight torch.Size([512])\n",
      "57 batch_norm10.bias torch.Size([512])\n",
      "58 batch_norm10.running_mean torch.Size([512])\n",
      "59 batch_norm10.running_var torch.Size([512])\n",
      "60 batch_norm10.num_batches_tracked torch.Size([])\n",
      "61 conv11_u.weight torch.Size([128, 512, 3, 3])\n",
      "62 conv11_v.weight torch.Size([512, 128, 1, 1])\n",
      "63 batch_norm11.weight torch.Size([512])\n",
      "64 batch_norm11.bias torch.Size([512])\n",
      "65 batch_norm11.running_mean torch.Size([512])\n",
      "66 batch_norm11.running_var torch.Size([512])\n",
      "67 batch_norm11.num_batches_tracked torch.Size([])\n",
      "68 conv12_u.weight torch.Size([128, 512, 3, 3])\n",
      "69 conv12_v.weight torch.Size([512, 128, 1, 1])\n",
      "70 batch_norm12.weight torch.Size([512])\n",
      "71 batch_norm12.bias torch.Size([512])\n",
      "72 batch_norm12.running_mean torch.Size([512])\n",
      "73 batch_norm12.running_var torch.Size([512])\n",
      "74 batch_norm12.num_batches_tracked torch.Size([])\n",
      "75 conv13_u.weight torch.Size([128, 512, 3, 3])\n",
      "76 conv13_v.weight torch.Size([512, 128, 1, 1])\n",
      "77 batch_norm13.weight torch.Size([512])\n",
      "78 batch_norm13.bias torch.Size([512])\n",
      "79 batch_norm13.running_mean torch.Size([512])\n",
      "80 batch_norm13.running_var torch.Size([512])\n",
      "81 batch_norm13.num_batches_tracked torch.Size([])\n",
      "82 conv14_u.weight torch.Size([128, 512, 3, 3])\n",
      "83 conv14_v.weight torch.Size([512, 128, 1, 1])\n",
      "84 batch_norm14.weight torch.Size([512])\n",
      "85 batch_norm14.bias torch.Size([512])\n",
      "86 batch_norm14.running_mean torch.Size([512])\n",
      "87 batch_norm14.running_var torch.Size([512])\n",
      "88 batch_norm14.num_batches_tracked torch.Size([])\n",
      "89 conv15_u.weight torch.Size([128, 512, 3, 3])\n",
      "90 conv15_v.weight torch.Size([512, 128, 1, 1])\n",
      "91 batch_norm15.weight torch.Size([512])\n",
      "92 batch_norm15.bias torch.Size([512])\n",
      "93 batch_norm15.running_mean torch.Size([512])\n",
      "94 batch_norm15.running_var torch.Size([512])\n",
      "95 batch_norm15.num_batches_tracked torch.Size([])\n",
      "96 conv16_u.weight torch.Size([128, 512, 3, 3])\n",
      "97 conv16_v.weight torch.Size([512, 128, 1, 1])\n",
      "98 batch_norm16.weight torch.Size([512])\n",
      "99 batch_norm16.bias torch.Size([512])\n",
      "100 batch_norm16.running_mean torch.Size([512])\n",
      "101 batch_norm16.running_var torch.Size([512])\n",
      "102 batch_norm16.num_batches_tracked torch.Size([])\n",
      "103 classifier.1.weight torch.Size([128, 512])\n",
      "104 classifier.2.weight torch.Size([512, 128])\n",
      "105 classifier.2.bias torch.Size([512])\n",
      "106 classifier.5.weight torch.Size([128, 512])\n",
      "107 classifier.6.weight torch.Size([512, 128])\n",
      "108 classifier.6.bias torch.Size([512])\n",
      "109 classifier.8.weight torch.Size([10, 512])\n",
      "110 classifier.8.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_counter(model):\n",
    "    num_params = 0\n",
    "    for param_index, (param_name, param) in enumerate(model.named_parameters()):\n",
    "        num_params += param.numel()\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowrank param: 8370634, fullrank param: 20560330\n"
     ]
    }
   ],
   "source": [
    "lowrank_param = param_counter(low_rank_model)\n",
    "fullrank_param = param_counter(full_rank_model)\n",
    "print(\"lowrank param: {}, fullrank param: {}\".format(lowrank_param, fullrank_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 0.4 GMac, params: 20.56 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(full_rank_model, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs: 0.29 GMac, params: 8.37 M\n"
     ]
    }
   ],
   "source": [
    "acs, params = get_model_complexity_info(low_rank_model, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "print(\"acs: {}, params: {}\".format(acs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_weights(model, low_rank_model, rank_factor):\n",
    "    # SVD version\n",
    "    reconstructed_aggregator = []\n",
    "\n",
    "    for item_index, (param_name, param) in enumerate(model.state_dict().items()):\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 6):\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 12):\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 18):\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 30):\n",
    "        if len(param.size()) == 4 and item_index not in range(0, 54):\n",
    "            # resize --> svd --> two layer\n",
    "            param_reshaped = param.view(param.size()[0], -1)\n",
    "            rank = min(param_reshaped.size()[0], param_reshaped.size()[1])\n",
    "            u, s, v = torch.svd(param_reshaped)\n",
    "\n",
    "            sliced_rank = int(rank/rank_factor)\n",
    "            u_weight = u * torch.sqrt(s)\n",
    "            v_weight = torch.sqrt(s) * v\n",
    "            u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "\n",
    "            u_weight_sliced_shape, v_weight_sliced_shape = u_weight_sliced.size(), v_weight_sliced.size()\n",
    "\n",
    "            model_weight_v = u_weight_sliced.view(u_weight_sliced_shape[0],\n",
    "                                                  u_weight_sliced_shape[1], 1, 1)\n",
    "            \n",
    "            model_weight_u = v_weight_sliced.t().view(v_weight_sliced_shape[1], \n",
    "                                                      param.size()[1], \n",
    "                                                      param.size()[2], \n",
    "                                                      param.size()[3])\n",
    "\n",
    "            reconstructed_aggregator.append(model_weight_u)\n",
    "            reconstructed_aggregator.append(model_weight_v)\n",
    "        elif len(param.size()) == 2 and \"classifier.\" in param_name and \"classifier.6.\" not in param_name:\n",
    "            print(param_name, param.size())\n",
    "            rank = min(param.size()[0], param.size()[1])\n",
    "            u, s, v = torch.svd(param)\n",
    "            sliced_rank = int(rank/rank_factor)\n",
    "            u_weight = u * torch.sqrt(s)\n",
    "            v_weight = torch.sqrt(s) * v\n",
    "            u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "\n",
    "            model_weight_v = u_weight_sliced\n",
    "            \n",
    "            model_weight_u = v_weight_sliced.t()\n",
    "\n",
    "            reconstructed_aggregator.append(model_weight_u)\n",
    "            reconstructed_aggregator.append(model_weight_v)            \n",
    "        else:\n",
    "            reconstructed_aggregator.append(param)\n",
    "            \n",
    "    \n",
    "    #for ra_index, ra in enumerate(reconstructed_aggregator):\n",
    "    #    print(\"ra index: {}, ra size: {}\".format(ra_index, ra.size()))\n",
    "            \n",
    "    model_counter = 0\n",
    "    reload_state_dict = {}\n",
    "    for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "        print(\"#### {}, {}, recons agg: {}， param: {}\".format(item_index, param_name, \n",
    "                                                                                reconstructed_aggregator[model_counter].size(),\n",
    "                                                                               param.size()))\n",
    "        assert (reconstructed_aggregator[model_counter].size() == param.size())\n",
    "        reload_state_dict[param_name] = reconstructed_aggregator[model_counter]\n",
    "        model_counter += 1\n",
    "    low_rank_model.load_state_dict(reload_state_dict)\n",
    "    return low_rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.1.weight torch.Size([512, 512])\n",
      "classifier.4.weight torch.Size([512, 512])\n",
      "#### 0, conv1.weight, recons agg: torch.Size([64, 3, 3, 3])， param: torch.Size([64, 3, 3, 3])\n",
      "#### 1, batch_norm1.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 2, batch_norm1.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 3, batch_norm1.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 4, batch_norm1.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 5, batch_norm1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 6, conv2.weight, recons agg: torch.Size([64, 64, 3, 3])， param: torch.Size([64, 64, 3, 3])\n",
      "#### 7, batch_norm2.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 8, batch_norm2.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 9, batch_norm2.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 10, batch_norm2.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 11, batch_norm2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 12, conv3.weight, recons agg: torch.Size([128, 64, 3, 3])， param: torch.Size([128, 64, 3, 3])\n",
      "#### 13, batch_norm3.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 14, batch_norm3.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 15, batch_norm3.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 16, batch_norm3.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 17, batch_norm3.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 18, conv4.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 19, batch_norm4.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 20, batch_norm4.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 21, batch_norm4.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 22, batch_norm4.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 23, batch_norm4.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 24, conv5.weight, recons agg: torch.Size([256, 128, 3, 3])， param: torch.Size([256, 128, 3, 3])\n",
      "#### 25, batch_norm5.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 26, batch_norm5.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 27, batch_norm5.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 28, batch_norm5.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 29, batch_norm5.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 30, conv6.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 31, batch_norm6.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 32, batch_norm6.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 33, batch_norm6.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 34, batch_norm6.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 35, batch_norm6.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 36, conv7.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 37, batch_norm7.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 38, batch_norm7.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 39, batch_norm7.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 40, batch_norm7.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 41, batch_norm7.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 42, conv8.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 43, batch_norm8.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 44, batch_norm8.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 45, batch_norm8.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 46, batch_norm8.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 47, batch_norm8.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 48, conv9.weight, recons agg: torch.Size([512, 256, 3, 3])， param: torch.Size([512, 256, 3, 3])\n",
      "#### 49, batch_norm9.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 50, batch_norm9.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 51, batch_norm9.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 52, batch_norm9.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 53, batch_norm9.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 54, conv10_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 55, conv10_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 56, batch_norm10.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 57, batch_norm10.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 58, batch_norm10.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 59, batch_norm10.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 60, batch_norm10.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 61, conv11_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 62, conv11_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 63, batch_norm11.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 64, batch_norm11.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 65, batch_norm11.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 66, batch_norm11.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 67, batch_norm11.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 68, conv12_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 69, conv12_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 70, batch_norm12.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 71, batch_norm12.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 72, batch_norm12.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 73, batch_norm12.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 74, batch_norm12.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 75, conv13_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 76, conv13_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 77, batch_norm13.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 78, batch_norm13.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 79, batch_norm13.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 80, batch_norm13.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 81, batch_norm13.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 82, conv14_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 83, conv14_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 84, batch_norm14.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 85, batch_norm14.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 86, batch_norm14.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 87, batch_norm14.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 88, batch_norm14.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 89, conv15_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 90, conv15_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 91, batch_norm15.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 92, batch_norm15.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 93, batch_norm15.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 94, batch_norm15.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 95, batch_norm15.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 96, conv16_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 97, conv16_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 98, batch_norm16.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 99, batch_norm16.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 100, batch_norm16.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 101, batch_norm16.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 102, batch_norm16.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 103, classifier.1.weight, recons agg: torch.Size([128, 512])， param: torch.Size([128, 512])\n",
      "#### 104, classifier.2.weight, recons agg: torch.Size([512, 128])， param: torch.Size([512, 128])\n",
      "#### 105, classifier.2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 106, classifier.5.weight, recons agg: torch.Size([128, 512])， param: torch.Size([128, 512])\n",
      "#### 107, classifier.6.weight, recons agg: torch.Size([512, 128])， param: torch.Size([512, 128])\n",
      "#### 108, classifier.6.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 109, classifier.8.weight, recons agg: torch.Size([10, 512])， param: torch.Size([10, 512])\n",
      "#### 110, classifier.8.bias, recons agg: torch.Size([10])， param: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LowRankVGG19(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv10_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv11_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv12_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv13_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv13_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv14_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv14_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv15_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv15_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv16_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv16_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batch_norm16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pooling5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=128, bias=False)\n",
       "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=512, out_features=128, bias=False)\n",
       "    (6): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose_weights(model=full_rank_model, low_rank_model=low_rank_model, rank_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model for resnet18 on cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_cifar10 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rank_model = ResNet18()\n",
    "low_rank_model = LowrankResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 3, 3])\n",
      "1 layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "2 layer1.0.bn1.weight torch.Size([64])\n",
      "3 layer1.0.bn1.bias torch.Size([64])\n",
      "4 layer1.0.bn1.running_mean torch.Size([64])\n",
      "5 layer1.0.bn1.running_var torch.Size([64])\n",
      "6 layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "7 layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "8 layer1.0.bn2.weight torch.Size([64])\n",
      "9 layer1.0.bn2.bias torch.Size([64])\n",
      "10 layer1.0.bn2.running_mean torch.Size([64])\n",
      "11 layer1.0.bn2.running_var torch.Size([64])\n",
      "12 layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "13 layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "14 layer1.1.bn1.weight torch.Size([64])\n",
      "15 layer1.1.bn1.bias torch.Size([64])\n",
      "16 layer1.1.bn1.running_mean torch.Size([64])\n",
      "17 layer1.1.bn1.running_var torch.Size([64])\n",
      "18 layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "19 layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "20 layer1.1.bn2.weight torch.Size([64])\n",
      "21 layer1.1.bn2.bias torch.Size([64])\n",
      "22 layer1.1.bn2.running_mean torch.Size([64])\n",
      "23 layer1.1.bn2.running_var torch.Size([64])\n",
      "24 layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "25 layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
      "26 layer2.0.bn1.weight torch.Size([128])\n",
      "27 layer2.0.bn1.bias torch.Size([128])\n",
      "28 layer2.0.bn1.running_mean torch.Size([128])\n",
      "29 layer2.0.bn1.running_var torch.Size([128])\n",
      "30 layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "31 layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "32 layer2.0.bn2.weight torch.Size([128])\n",
      "33 layer2.0.bn2.bias torch.Size([128])\n",
      "34 layer2.0.bn2.running_mean torch.Size([128])\n",
      "35 layer2.0.bn2.running_var torch.Size([128])\n",
      "36 layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "37 layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])\n",
      "38 layer2.0.shortcut.1.weight torch.Size([128])\n",
      "39 layer2.0.shortcut.1.bias torch.Size([128])\n",
      "40 layer2.0.shortcut.1.running_mean torch.Size([128])\n",
      "41 layer2.0.shortcut.1.running_var torch.Size([128])\n",
      "42 layer2.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "43 layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "44 layer2.1.bn1.weight torch.Size([128])\n",
      "45 layer2.1.bn1.bias torch.Size([128])\n",
      "46 layer2.1.bn1.running_mean torch.Size([128])\n",
      "47 layer2.1.bn1.running_var torch.Size([128])\n",
      "48 layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "49 layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "50 layer2.1.bn2.weight torch.Size([128])\n",
      "51 layer2.1.bn2.bias torch.Size([128])\n",
      "52 layer2.1.bn2.running_mean torch.Size([128])\n",
      "53 layer2.1.bn2.running_var torch.Size([128])\n",
      "54 layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "55 layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
      "56 layer3.0.bn1.weight torch.Size([256])\n",
      "57 layer3.0.bn1.bias torch.Size([256])\n",
      "58 layer3.0.bn1.running_mean torch.Size([256])\n",
      "59 layer3.0.bn1.running_var torch.Size([256])\n",
      "60 layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "61 layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "62 layer3.0.bn2.weight torch.Size([256])\n",
      "63 layer3.0.bn2.bias torch.Size([256])\n",
      "64 layer3.0.bn2.running_mean torch.Size([256])\n",
      "65 layer3.0.bn2.running_var torch.Size([256])\n",
      "66 layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "67 layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])\n",
      "68 layer3.0.shortcut.1.weight torch.Size([256])\n",
      "69 layer3.0.shortcut.1.bias torch.Size([256])\n",
      "70 layer3.0.shortcut.1.running_mean torch.Size([256])\n",
      "71 layer3.0.shortcut.1.running_var torch.Size([256])\n",
      "72 layer3.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "73 layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "74 layer3.1.bn1.weight torch.Size([256])\n",
      "75 layer3.1.bn1.bias torch.Size([256])\n",
      "76 layer3.1.bn1.running_mean torch.Size([256])\n",
      "77 layer3.1.bn1.running_var torch.Size([256])\n",
      "78 layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "79 layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "80 layer3.1.bn2.weight torch.Size([256])\n",
      "81 layer3.1.bn2.bias torch.Size([256])\n",
      "82 layer3.1.bn2.running_mean torch.Size([256])\n",
      "83 layer3.1.bn2.running_var torch.Size([256])\n",
      "84 layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "85 layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "86 layer4.0.bn1.weight torch.Size([512])\n",
      "87 layer4.0.bn1.bias torch.Size([512])\n",
      "88 layer4.0.bn1.running_mean torch.Size([512])\n",
      "89 layer4.0.bn1.running_var torch.Size([512])\n",
      "90 layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "91 layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "92 layer4.0.bn2.weight torch.Size([512])\n",
      "93 layer4.0.bn2.bias torch.Size([512])\n",
      "94 layer4.0.bn2.running_mean torch.Size([512])\n",
      "95 layer4.0.bn2.running_var torch.Size([512])\n",
      "96 layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "97 layer4.0.shortcut.0.weight torch.Size([512, 256, 1, 1])\n",
      "98 layer4.0.shortcut.1.weight torch.Size([512])\n",
      "99 layer4.0.shortcut.1.bias torch.Size([512])\n",
      "100 layer4.0.shortcut.1.running_mean torch.Size([512])\n",
      "101 layer4.0.shortcut.1.running_var torch.Size([512])\n",
      "102 layer4.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "103 layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "104 layer4.1.bn1.weight torch.Size([512])\n",
      "105 layer4.1.bn1.bias torch.Size([512])\n",
      "106 layer4.1.bn1.running_mean torch.Size([512])\n",
      "107 layer4.1.bn1.running_var torch.Size([512])\n",
      "108 layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "109 layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "110 layer4.1.bn2.weight torch.Size([512])\n",
      "111 layer4.1.bn2.bias torch.Size([512])\n",
      "112 layer4.1.bn2.running_mean torch.Size([512])\n",
      "113 layer4.1.bn2.running_var torch.Size([512])\n",
      "114 layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "115 linear.weight torch.Size([10, 512])\n",
      "116 linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(full_rank_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): LowrankBasicBlock(\n",
      "      (conv1_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(low_rank_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight torch.Size([64, 3, 3, 3])\n",
      "1 layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "2 layer1.0.bn1.weight torch.Size([64])\n",
      "3 layer1.0.bn1.bias torch.Size([64])\n",
      "4 layer1.0.bn1.running_mean torch.Size([64])\n",
      "5 layer1.0.bn1.running_var torch.Size([64])\n",
      "6 layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "7 layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "8 layer1.0.bn2.weight torch.Size([64])\n",
      "9 layer1.0.bn2.bias torch.Size([64])\n",
      "10 layer1.0.bn2.running_mean torch.Size([64])\n",
      "11 layer1.0.bn2.running_var torch.Size([64])\n",
      "12 layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "13 layer1.1.conv1_u.weight torch.Size([16, 64, 3, 3])\n",
      "14 layer1.1.conv1_v.weight torch.Size([64, 16, 1, 1])\n",
      "15 layer1.1.bn1.weight torch.Size([64])\n",
      "16 layer1.1.bn1.bias torch.Size([64])\n",
      "17 layer1.1.bn1.running_mean torch.Size([64])\n",
      "18 layer1.1.bn1.running_var torch.Size([64])\n",
      "19 layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "20 layer1.1.conv2_u.weight torch.Size([16, 64, 3, 3])\n",
      "21 layer1.1.conv2_v.weight torch.Size([64, 16, 1, 1])\n",
      "22 layer1.1.bn2.weight torch.Size([64])\n",
      "23 layer1.1.bn2.bias torch.Size([64])\n",
      "24 layer1.1.bn2.running_mean torch.Size([64])\n",
      "25 layer1.1.bn2.running_var torch.Size([64])\n",
      "26 layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "27 layer2.0.conv1_u.weight torch.Size([32, 64, 3, 3])\n",
      "28 layer2.0.conv1_v.weight torch.Size([128, 32, 1, 1])\n",
      "29 layer2.0.bn1.weight torch.Size([128])\n",
      "30 layer2.0.bn1.bias torch.Size([128])\n",
      "31 layer2.0.bn1.running_mean torch.Size([128])\n",
      "32 layer2.0.bn1.running_var torch.Size([128])\n",
      "33 layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "34 layer2.0.conv2_u.weight torch.Size([32, 128, 3, 3])\n",
      "35 layer2.0.conv2_v.weight torch.Size([128, 32, 1, 1])\n",
      "36 layer2.0.bn2.weight torch.Size([128])\n",
      "37 layer2.0.bn2.bias torch.Size([128])\n",
      "38 layer2.0.bn2.running_mean torch.Size([128])\n",
      "39 layer2.0.bn2.running_var torch.Size([128])\n",
      "40 layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "41 layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])\n",
      "42 layer2.0.shortcut.1.weight torch.Size([128])\n",
      "43 layer2.0.shortcut.1.bias torch.Size([128])\n",
      "44 layer2.0.shortcut.1.running_mean torch.Size([128])\n",
      "45 layer2.0.shortcut.1.running_var torch.Size([128])\n",
      "46 layer2.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "47 layer2.1.conv1_u.weight torch.Size([32, 128, 3, 3])\n",
      "48 layer2.1.conv1_v.weight torch.Size([128, 32, 1, 1])\n",
      "49 layer2.1.bn1.weight torch.Size([128])\n",
      "50 layer2.1.bn1.bias torch.Size([128])\n",
      "51 layer2.1.bn1.running_mean torch.Size([128])\n",
      "52 layer2.1.bn1.running_var torch.Size([128])\n",
      "53 layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "54 layer2.1.conv2_u.weight torch.Size([32, 128, 3, 3])\n",
      "55 layer2.1.conv2_v.weight torch.Size([128, 32, 1, 1])\n",
      "56 layer2.1.bn2.weight torch.Size([128])\n",
      "57 layer2.1.bn2.bias torch.Size([128])\n",
      "58 layer2.1.bn2.running_mean torch.Size([128])\n",
      "59 layer2.1.bn2.running_var torch.Size([128])\n",
      "60 layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "61 layer3.0.conv1_u.weight torch.Size([64, 128, 3, 3])\n",
      "62 layer3.0.conv1_v.weight torch.Size([256, 64, 1, 1])\n",
      "63 layer3.0.bn1.weight torch.Size([256])\n",
      "64 layer3.0.bn1.bias torch.Size([256])\n",
      "65 layer3.0.bn1.running_mean torch.Size([256])\n",
      "66 layer3.0.bn1.running_var torch.Size([256])\n",
      "67 layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "68 layer3.0.conv2_u.weight torch.Size([64, 256, 3, 3])\n",
      "69 layer3.0.conv2_v.weight torch.Size([256, 64, 1, 1])\n",
      "70 layer3.0.bn2.weight torch.Size([256])\n",
      "71 layer3.0.bn2.bias torch.Size([256])\n",
      "72 layer3.0.bn2.running_mean torch.Size([256])\n",
      "73 layer3.0.bn2.running_var torch.Size([256])\n",
      "74 layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "75 layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])\n",
      "76 layer3.0.shortcut.1.weight torch.Size([256])\n",
      "77 layer3.0.shortcut.1.bias torch.Size([256])\n",
      "78 layer3.0.shortcut.1.running_mean torch.Size([256])\n",
      "79 layer3.0.shortcut.1.running_var torch.Size([256])\n",
      "80 layer3.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "81 layer3.1.conv1_u.weight torch.Size([64, 256, 3, 3])\n",
      "82 layer3.1.conv1_v.weight torch.Size([256, 64, 1, 1])\n",
      "83 layer3.1.bn1.weight torch.Size([256])\n",
      "84 layer3.1.bn1.bias torch.Size([256])\n",
      "85 layer3.1.bn1.running_mean torch.Size([256])\n",
      "86 layer3.1.bn1.running_var torch.Size([256])\n",
      "87 layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "88 layer3.1.conv2_u.weight torch.Size([64, 256, 3, 3])\n",
      "89 layer3.1.conv2_v.weight torch.Size([256, 64, 1, 1])\n",
      "90 layer3.1.bn2.weight torch.Size([256])\n",
      "91 layer3.1.bn2.bias torch.Size([256])\n",
      "92 layer3.1.bn2.running_mean torch.Size([256])\n",
      "93 layer3.1.bn2.running_var torch.Size([256])\n",
      "94 layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "95 layer4.0.conv1_u.weight torch.Size([128, 256, 3, 3])\n",
      "96 layer4.0.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "97 layer4.0.bn1.weight torch.Size([512])\n",
      "98 layer4.0.bn1.bias torch.Size([512])\n",
      "99 layer4.0.bn1.running_mean torch.Size([512])\n",
      "100 layer4.0.bn1.running_var torch.Size([512])\n",
      "101 layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "102 layer4.0.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "103 layer4.0.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "104 layer4.0.bn2.weight torch.Size([512])\n",
      "105 layer4.0.bn2.bias torch.Size([512])\n",
      "106 layer4.0.bn2.running_mean torch.Size([512])\n",
      "107 layer4.0.bn2.running_var torch.Size([512])\n",
      "108 layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "109 layer4.0.shortcut.0.weight torch.Size([512, 256, 1, 1])\n",
      "110 layer4.0.shortcut.1.weight torch.Size([512])\n",
      "111 layer4.0.shortcut.1.bias torch.Size([512])\n",
      "112 layer4.0.shortcut.1.running_mean torch.Size([512])\n",
      "113 layer4.0.shortcut.1.running_var torch.Size([512])\n",
      "114 layer4.0.shortcut.1.num_batches_tracked torch.Size([])\n",
      "115 layer4.1.conv1_u.weight torch.Size([128, 512, 3, 3])\n",
      "116 layer4.1.conv1_v.weight torch.Size([512, 128, 1, 1])\n",
      "117 layer4.1.bn1.weight torch.Size([512])\n",
      "118 layer4.1.bn1.bias torch.Size([512])\n",
      "119 layer4.1.bn1.running_mean torch.Size([512])\n",
      "120 layer4.1.bn1.running_var torch.Size([512])\n",
      "121 layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "122 layer4.1.conv2_u.weight torch.Size([128, 512, 3, 3])\n",
      "123 layer4.1.conv2_v.weight torch.Size([512, 128, 1, 1])\n",
      "124 layer4.1.bn2.weight torch.Size([512])\n",
      "125 layer4.1.bn2.bias torch.Size([512])\n",
      "126 layer4.1.bn2.running_mean torch.Size([512])\n",
      "127 layer4.1.bn2.running_var torch.Size([512])\n",
      "128 layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "129 linear.weight torch.Size([10, 512])\n",
      "130 linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "    print(item_index, param_name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_weights(model, low_rank_model, rank_factor):\n",
    "    # SVD version\n",
    "    reconstructed_aggregator = []\n",
    "\n",
    "    for item_index, (param_name, param) in enumerate(model.state_dict().items()):\n",
    "        if len(param.size()) == 4 and item_index not in range(0, 13) and \".shortcut.\" not in param_name:\n",
    "        #if len(param.size()) == 4 and item_index not in range(0, 85) and \".shortcut.\" not in param_name:\n",
    "            # resize --> svd --> two layer\n",
    "            param_reshaped = param.view(param.size()[0], -1)\n",
    "            rank = min(param_reshaped.size()[0], param_reshaped.size()[1])\n",
    "            u, s, v = torch.svd(param_reshaped)\n",
    "\n",
    "            sliced_rank = int(rank/rank_factor)\n",
    "            u_weight = u * torch.sqrt(s)\n",
    "            v_weight = torch.sqrt(s) * v\n",
    "            u_weight_sliced, v_weight_sliced = u_weight[:, 0:sliced_rank], v_weight[:, 0:sliced_rank]\n",
    "\n",
    "            u_weight_sliced_shape, v_weight_sliced_shape = u_weight_sliced.size(), v_weight_sliced.size()\n",
    "\n",
    "            model_weight_v = u_weight_sliced.view(u_weight_sliced_shape[0],\n",
    "                                                  u_weight_sliced_shape[1], 1, 1)\n",
    "            \n",
    "            model_weight_u = v_weight_sliced.t().view(v_weight_sliced_shape[1], \n",
    "                                                      param.size()[1], \n",
    "                                                      param.size()[2], \n",
    "                                                      param.size()[3])\n",
    "\n",
    "            reconstructed_aggregator.append(model_weight_u)\n",
    "            reconstructed_aggregator.append(model_weight_v)           \n",
    "        else:\n",
    "            reconstructed_aggregator.append(param)\n",
    "            \n",
    "    \n",
    "    #for ra_index, ra in enumerate(reconstructed_aggregator):\n",
    "    #    print(\"ra index: {}, ra size: {}\".format(ra_index, ra.size()))\n",
    "            \n",
    "    model_counter = 0\n",
    "    reload_state_dict = {}\n",
    "    for item_index, (param_name, param) in enumerate(low_rank_model.state_dict().items()):\n",
    "        print(\"#### {}, {}, recons agg: {}， param: {}\".format(item_index, param_name, \n",
    "                                                                                reconstructed_aggregator[model_counter].size(),\n",
    "                                                                               param.size()))\n",
    "        assert (reconstructed_aggregator[model_counter].size() == param.size())\n",
    "        reload_state_dict[param_name] = reconstructed_aggregator[model_counter]\n",
    "        model_counter += 1\n",
    "    low_rank_model.load_state_dict(reload_state_dict)\n",
    "    return low_rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 0, conv1.weight, recons agg: torch.Size([64, 3, 3, 3])， param: torch.Size([64, 3, 3, 3])\n",
      "#### 1, layer1.0.conv1.weight, recons agg: torch.Size([64, 64, 3, 3])， param: torch.Size([64, 64, 3, 3])\n",
      "#### 2, layer1.0.bn1.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 3, layer1.0.bn1.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 4, layer1.0.bn1.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 5, layer1.0.bn1.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 6, layer1.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 7, layer1.0.conv2.weight, recons agg: torch.Size([64, 64, 3, 3])， param: torch.Size([64, 64, 3, 3])\n",
      "#### 8, layer1.0.bn2.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 9, layer1.0.bn2.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 10, layer1.0.bn2.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 11, layer1.0.bn2.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 12, layer1.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 13, layer1.1.conv1.weight, recons agg: torch.Size([64, 64, 3, 3])， param: torch.Size([64, 64, 3, 3])\n",
      "#### 14, layer1.1.bn1.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 15, layer1.1.bn1.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 16, layer1.1.bn1.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 17, layer1.1.bn1.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 18, layer1.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 19, layer1.1.conv2.weight, recons agg: torch.Size([64, 64, 3, 3])， param: torch.Size([64, 64, 3, 3])\n",
      "#### 20, layer1.1.bn2.weight, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 21, layer1.1.bn2.bias, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 22, layer1.1.bn2.running_mean, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 23, layer1.1.bn2.running_var, recons agg: torch.Size([64])， param: torch.Size([64])\n",
      "#### 24, layer1.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 25, layer2.0.conv1.weight, recons agg: torch.Size([128, 64, 3, 3])， param: torch.Size([128, 64, 3, 3])\n",
      "#### 26, layer2.0.bn1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 27, layer2.0.bn1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 28, layer2.0.bn1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 29, layer2.0.bn1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 30, layer2.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 31, layer2.0.conv2.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 32, layer2.0.bn2.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 33, layer2.0.bn2.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 34, layer2.0.bn2.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 35, layer2.0.bn2.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 36, layer2.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 37, layer2.0.shortcut.0.weight, recons agg: torch.Size([128, 64, 1, 1])， param: torch.Size([128, 64, 1, 1])\n",
      "#### 38, layer2.0.shortcut.1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 39, layer2.0.shortcut.1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 40, layer2.0.shortcut.1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 41, layer2.0.shortcut.1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 42, layer2.0.shortcut.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 43, layer2.1.conv1.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 44, layer2.1.bn1.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 45, layer2.1.bn1.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 46, layer2.1.bn1.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 47, layer2.1.bn1.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 48, layer2.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 49, layer2.1.conv2.weight, recons agg: torch.Size([128, 128, 3, 3])， param: torch.Size([128, 128, 3, 3])\n",
      "#### 50, layer2.1.bn2.weight, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 51, layer2.1.bn2.bias, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 52, layer2.1.bn2.running_mean, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 53, layer2.1.bn2.running_var, recons agg: torch.Size([128])， param: torch.Size([128])\n",
      "#### 54, layer2.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 55, layer3.0.conv1.weight, recons agg: torch.Size([256, 128, 3, 3])， param: torch.Size([256, 128, 3, 3])\n",
      "#### 56, layer3.0.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 57, layer3.0.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 58, layer3.0.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 59, layer3.0.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 60, layer3.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 61, layer3.0.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 62, layer3.0.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 63, layer3.0.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 64, layer3.0.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 65, layer3.0.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 66, layer3.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 67, layer3.0.shortcut.0.weight, recons agg: torch.Size([256, 128, 1, 1])， param: torch.Size([256, 128, 1, 1])\n",
      "#### 68, layer3.0.shortcut.1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 69, layer3.0.shortcut.1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 70, layer3.0.shortcut.1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 71, layer3.0.shortcut.1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 72, layer3.0.shortcut.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 73, layer3.1.conv1.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 74, layer3.1.bn1.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 75, layer3.1.bn1.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 76, layer3.1.bn1.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 77, layer3.1.bn1.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 78, layer3.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 79, layer3.1.conv2.weight, recons agg: torch.Size([256, 256, 3, 3])， param: torch.Size([256, 256, 3, 3])\n",
      "#### 80, layer3.1.bn2.weight, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 81, layer3.1.bn2.bias, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 82, layer3.1.bn2.running_mean, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 83, layer3.1.bn2.running_var, recons agg: torch.Size([256])， param: torch.Size([256])\n",
      "#### 84, layer3.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 85, layer4.0.conv1_u.weight, recons agg: torch.Size([128, 256, 3, 3])， param: torch.Size([128, 256, 3, 3])\n",
      "#### 86, layer4.0.conv1_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 87, layer4.0.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 88, layer4.0.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 89, layer4.0.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 90, layer4.0.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 91, layer4.0.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 92, layer4.0.conv2_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 93, layer4.0.conv2_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 94, layer4.0.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 95, layer4.0.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 96, layer4.0.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 97, layer4.0.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 98, layer4.0.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 99, layer4.0.shortcut.0.weight, recons agg: torch.Size([512, 256, 1, 1])， param: torch.Size([512, 256, 1, 1])\n",
      "#### 100, layer4.0.shortcut.1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 101, layer4.0.shortcut.1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 102, layer4.0.shortcut.1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 103, layer4.0.shortcut.1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 104, layer4.0.shortcut.1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 105, layer4.1.conv1_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 106, layer4.1.conv1_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 107, layer4.1.bn1.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 108, layer4.1.bn1.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 109, layer4.1.bn1.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 110, layer4.1.bn1.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 111, layer4.1.bn1.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 112, layer4.1.conv2_u.weight, recons agg: torch.Size([128, 512, 3, 3])， param: torch.Size([128, 512, 3, 3])\n",
      "#### 113, layer4.1.conv2_v.weight, recons agg: torch.Size([512, 128, 1, 1])， param: torch.Size([512, 128, 1, 1])\n",
      "#### 114, layer4.1.bn2.weight, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 115, layer4.1.bn2.bias, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 116, layer4.1.bn2.running_mean, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 117, layer4.1.bn2.running_var, recons agg: torch.Size([512])， param: torch.Size([512])\n",
      "#### 118, layer4.1.bn2.num_batches_tracked, recons agg: torch.Size([])， param: torch.Size([])\n",
      "#### 119, linear.weight, recons agg: torch.Size([10, 512])， param: torch.Size([10, 512])\n",
      "#### 120, linear.bias, recons agg: torch.Size([10])， param: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HybridResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): LowrankBasicBlock(\n",
       "      (conv1_u): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): LowrankBasicBlock(\n",
       "      (conv1_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv1_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_u): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2_v): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose_weights(model=full_rank_model, low_rank_model=low_rank_model, rank_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
